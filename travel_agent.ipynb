{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting phidata\n",
      "  Downloading phidata-2.7.10-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (1.59.7)\n",
      "Collecting openai\n",
      "  Downloading openai-1.62.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-7.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting docstring-parser (from phidata)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: gitpython in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (3.1.43)\n",
      "Requirement already satisfied: httpx in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (0.27.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (2.10.6)\n",
      "Requirement already satisfied: pydantic-settings in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (2.7.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (6.0.1)\n",
      "Requirement already satisfied: rich in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (13.7.1)\n",
      "Requirement already satisfied: tomli in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (2.0.1)\n",
      "Requirement already satisfied: typer in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from phidata) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Collecting click>=8.1.8 (from duckduckgo-search)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting primp>=0.11.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.12.1-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.8->duckduckgo-search) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpx->phidata) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpx->phidata) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->phidata) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic->phidata) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic->phidata) (2.27.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from gitpython->phidata) (4.0.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from rich->phidata) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from rich->phidata) (2.19.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from typer->phidata) (1.5.4)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->phidata) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->phidata) (0.1.0)\n",
      "Downloading phidata-2.7.10-py3-none-any.whl (716 kB)\n",
      "   ---------------------------------------- 0.0/716.9 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 524.3/716.9 kB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 524.3/716.9 kB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- 716.9/716.9 kB 969.7 kB/s eta 0:00:00\n",
      "Downloading openai-1.62.0-py3-none-any.whl (464 kB)\n",
      "Downloading duckduckgo_search-7.3.2-py3-none-any.whl (19 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.9/3.8 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading primp-0.12.1-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.9/3.1 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.1 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.1 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.1 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.1 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: primp, lxml, docstring-parser, click, duckduckgo-search, openai, phidata\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 5.2.1\n",
      "    Uninstalling lxml-5.2.1:\n",
      "      Successfully uninstalled lxml-5.2.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.7\n",
      "    Uninstalling openai-1.59.7:\n",
      "      Successfully uninstalled openai-1.59.7\n",
      "Successfully installed click-8.1.8 docstring-parser-0.16 duckduckgo-search-7.3.2 lxml-5.3.1 openai-1.62.0 phidata-2.7.10 primp-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U phidata openai duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (1.62.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from phi.agent import Agent\n",
    "#from phi.model.groq import Groq  # Assuming this is how you import Groq Llama\n",
    "from phi.tools.serpapi_tools import SerpApiTools\n",
    "\n",
    "import openai\n",
    "\n",
    "\n",
    "# Initialize page config\n",
    "st.set_page_config(\n",
    "    page_title=\"AI Travel Planner\",\n",
    "    page_icon=\"üåé\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Enhanced Custom CSS for improved UI\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    :root {\n",
    "        --primary-color: #2E86C1;\n",
    "        --accent-color: #FF6B6B;\n",
    "        --background-light: #F8F9FA;\n",
    "        --text-color: #2C3E50;\n",
    "        --hover-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);\n",
    "    }\n",
    "\n",
    "    .main {\n",
    "        padding: 2rem;\n",
    "        max-width: 1200px;\n",
    "        margin: 0 auto;\n",
    "    }\n",
    "\n",
    "    .stButton > button {\n",
    "        width: 100%;\n",
    "        border-radius: 8px;\n",
    "        height: 3em;\n",
    "        background-color: var(--accent-color) !important;\n",
    "        color: white !important;\n",
    "        font-weight: bold;\n",
    "        font-size: 1rem;\n",
    "        transition: all 0.3s ease;\n",
    "    }\n",
    "\n",
    "    .stButton > button:hover {\n",
    "        transform: translateY(-2px);\n",
    "        box-shadow: var(--hover-shadow);\n",
    "        background-color: #FF4A4A !important;\n",
    "    }\n",
    "\n",
    "    .sidebar .element-container {\n",
    "        background-color: var(--background-light);\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        margin-bottom: 1rem;\n",
    "        box-shadow: 0 2px 8px rgba(0,0,0,0.05);\n",
    "    }\n",
    "\n",
    "    .stExpander {\n",
    "        background-color: #262730;\n",
    "        border-radius: 10px;\n",
    "        padding: 1rem;\n",
    "        border: none;\n",
    "        box-shadow: 0 2px 8px rgba(0,0,0,0.05);\n",
    "    }\n",
    "\n",
    "    .travel-summary {\n",
    "        background-color: #262730;\n",
    "        padding: 1.5rem;\n",
    "        border-radius: 10px;\n",
    "        margin-bottom: 2rem;\n",
    "        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
    "    }\n",
    "\n",
    "    .travel-summary h4 {\n",
    "        color: var(--primary-color);\n",
    "        margin-bottom: 0.5rem;\n",
    "    }\n",
    "\n",
    "    .spinner-text {\n",
    "        font-size: 1.2rem;\n",
    "        font-weight: bold;\n",
    "        color: var(--primary-color);\n",
    "    }\n",
    "\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar configuration\n",
    "with st.sidebar:\n",
    "    st.image(\"https://img.icons8.com/clouds/200/airplane-take-off.png\")\n",
    "    st.title(\"Trip Settings\")\n",
    "    \n",
    "    # User inputs for API keys\n",
    "    groq_api_key = st.text_input(\"üîë Enter your Groq API Key\", type=\"password\")\n",
    "    serpapi_key = st.text_input(\"üîë Enter your SerpAPI Key\", type=\"password\")\n",
    "    \n",
    "    destination = st.text_input(\"üåç Where would you like to go?\", \"\")\n",
    "    duration = st.number_input(\"üìÖ How many days?\", min_value=1, max_value=30, value=5)\n",
    "    \n",
    "    budget = st.select_slider(\n",
    "        \"üí∞ What's your budget level?\",\n",
    "        options=[\"Budget\", \"Moderate\", \"Luxury\"],\n",
    "        value=\"Moderate\"\n",
    "    )\n",
    "    \n",
    "    travel_style = st.multiselect(\n",
    "        \"üéØ Travel Style\",\n",
    "        [\"Culture\", \"Nature\", \"Adventure\", \"Relaxation\", \"Food\", \"Shopping\"],\n",
    "        [\"Culture\", \"Nature\"]\n",
    "    )\n",
    "\n",
    "# Initialize session state variables\n",
    "if 'travel_plan' not in st.session_state:\n",
    "    st.session_state.travel_plan = None\n",
    "if 'qa_expanded' not in st.session_state:\n",
    "    st.session_state.qa_expanded = False\n",
    "\n",
    "# Add loading state container\n",
    "loading_container = st.empty()\n",
    "\n",
    "try:\n",
    "    # Set API keys in environment variables\n",
    "    #os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "    os.environ[\"SERP_API_KEY\"] = \"9861d0b93e24164ecb07c9fbd1d6020f085279765433cd4a65432d766bc40f82\"\n",
    "\n",
    "    # Initialize travel agent with Groq Llama model and SerpAPI\n",
    "    travel_agent = Agent(\n",
    "        name=\"Travel Planner\",\n",
    "        model=Groq(id=\"llama-3.3-70b-versatile\"),  # Adjust if necessary based on actual import\n",
    "        tools=[SerpApiTools()],\n",
    "        instructions=[\n",
    "            \"You are a travel planning assistant using Groq Llama.\",\n",
    "            \"Help users plan their trips by researching destinations, finding attractions, suggesting accommodations, and providing transportation options.\",\n",
    "            \"Give me relevant live Links of each places and hotels you provide by searching on internet (It's important)\",\n",
    "            \"Always verify information is current before making recommendations.\"\n",
    "        ],\n",
    "        show_tool_calls=True,\n",
    "        markdown=True\n",
    "    )\n",
    "\n",
    "    # Main UI\n",
    "    st.title(\"üåé AI Travel Planner\")\n",
    "    \n",
    "    st.markdown(f\"\"\"\n",
    "        <div class=\"travel-summary\">\n",
    "            <h4>Welcome to your personal AI Travel Assistant! üåü</h4>\n",
    "            <p>Let me help you create your perfect travel itinerary based on your preferences.</p>\n",
    "            <p><strong>Destination:</strong> {destination}</p>\n",
    "            <p><strong>Duration:</strong> {duration} days</p>\n",
    "            <p><strong>Budget:</strong> {budget}</p>\n",
    "            <p><strong>Travel Styles:</strong> {', '.join(travel_style)}</p>\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Generate button\n",
    "    if st.button(\"‚ú® Generate My Perfect Travel Plan\", type=\"primary\"):\n",
    "        if destination:\n",
    "            try:\n",
    "                with st.spinner(\"üîç Researching and planning your trip...\"):\n",
    "                    prompt = f\"\"\"Create a comprehensive travel plan for {destination} for {duration} days.\n",
    "\n",
    "    Travel Preferences:\n",
    "    - Budget Level: {budget}\n",
    "    - Travel Styles: {', '.join(travel_style)}\n",
    "\n",
    "    Please provide a detailed itinerary that includes:\n",
    "\n",
    "    1. üåû Best Time to Visit\n",
    "    - Seasonal highlights\n",
    "    - Weather considerations\n",
    "\n",
    "    2. üè® Accommodation Recommendations\n",
    "    - {budget} range hotels/stays\n",
    "    - Locations and proximity to attractions\n",
    "\n",
    "    3. üó∫Ô∏è Day-by-Day Itinerary\n",
    "    - Detailed daily activities\n",
    "    - Must-visit attractions\n",
    "    - Local experiences aligned with travel styles\n",
    "\n",
    "    4. üçΩÔ∏è Culinary Experiences\n",
    "    - Local cuisine highlights\n",
    "    - Recommended restaurants\n",
    "    - Food experiences matching travel style\n",
    "\n",
    "    5. üí° Practical Travel Tips\n",
    "    - Local transportation options\n",
    "    - Cultural etiquette\n",
    "    - Safety recommendations\n",
    "    - Estimated daily budget breakdown\n",
    "\n",
    "    6. üí∞ Estimated Total Trip Cost\n",
    "    - Breakdown of expenses\n",
    "    - Money-saving tips\n",
    "\n",
    "    Please provide source and relevant links without fail.\n",
    "\n",
    "    Format the response in a clear, easy-to-read markdown format with headings and bullet points.\n",
    "                    \"\"\"\n",
    "                    response = travel_agent.run(prompt)\n",
    "                    if hasattr(response, 'content'):\n",
    "                        clean_response = response.content.replace('‚à£', '|').replace('\\n\\n\\n', '\\n\\n')\n",
    "                        st.session_state.travel_plan = clean_response\n",
    "                        st.markdown(clean_response)\n",
    "                    else:\n",
    "                        st.session_state.travel_plan = str(response)\n",
    "                        st.markdown(str(response))\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error generating travel plan: {str(e)}\")\n",
    "                st.info(\"Please try again in a few moments.\")\n",
    "        else:\n",
    "            st.warning(\"Please enter a destination\")\n",
    "\n",
    "    # Q&A Section\n",
    "    st.divider()\n",
    "    \n",
    "    # Use st.expander with a key to maintain state\n",
    "    qa_expander = st.expander(\"ü§î Ask a specific question about your destination or travel plan\", expanded=st.session_state.qa_expanded)\n",
    "    \n",
    "    with qa_expander:\n",
    "        # Store the expanded state\n",
    "        st.session_state.qa_expanded = True\n",
    "        \n",
    "        question = st.text_input(\"Your question:\", placeholder=\"What would you like to know about your trip?\")\n",
    "        \n",
    "        if st.button(\"Get Answer\", key=\"qa_button\"):\n",
    "            if question and st.session_state.travel_plan:\n",
    "                with st.spinner(\"üîç Finding answer...\"):\n",
    "                    try:\n",
    "                        # Combine the original travel plan with the new question for context\n",
    "                        context_question = f\"\"\"\n",
    "                        I have a travel plan for {destination}. Here's the existing plan:\n",
    "                        {st.session_state.travel_plan}\n",
    "\n",
    "                        Now, please answer this specific question: {question}\n",
    "                        \n",
    "                        Provide a focused, concise answer that relates to the existing travel plan if possible.\n",
    "                        \"\"\"\n",
    "                        response = travel_agent.run(context_question)\n",
    "                        if hasattr(response, 'content'):\n",
    "                            st.markdown(response.content)\n",
    "                        else:\n",
    "                            st.markdown(str(response))\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Error getting answer: {str(e)}\")\n",
    "            elif not st.session_state.travel_plan:\n",
    "                st.warning(\"Please generate a travel plan first before asking questions.\")\n",
    "            else:\n",
    "                st.warning(\"Please enter a question\")\n",
    "\n",
    "except Exception as e:\n",
    "    st.error(f\"Application Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Traveler's Guide to Puerto Rico!\n",
      "Choose a destination to learn more:\n",
      "Old San Juan\n",
      "El Yunque National Forest\n",
      "Bioluminescent Bay\n",
      "Destination: Old San Juan\n",
      "Description: Historic district known for its colorful buildings, cobblestone streets, and historic forts.\n",
      "Things to do:\n",
      "- Visit El Morro fort\n",
      "- Explore shops and restaurants on Calle Fortaleza\n",
      "- Walk along Paseo de la Princesa.\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with information on popular destinations in Puerto Rico\n",
    "puerto_rico_guide = {\n",
    "    \"Old San Juan\": {\n",
    "        \"Description\": \"Historic district known for its colorful buildings, cobblestone streets, and historic forts.\",\n",
    "        \"Things to do\": [\"Visit El Morro fort\", \"Explore shops and restaurants on Calle Fortaleza\", \"Walk along Paseo de la Princesa.\"]\n",
    "    },\n",
    "    \"El Yunque National Forest\": {\n",
    "        \"Description\": \"Tropical rainforest with hiking trails, waterfalls, and scenic views.\",\n",
    "        \"Things to do\": [\"Hike to La Mina Falls\", \"Take a guided tour with a park ranger\", \"Visit Yokahu Tower for panoramic views.\"]\n",
    "    },\n",
    "    \"Bioluminescent Bay\": {\n",
    "        \"Description\": \"Magical bay where water glows blue-green at night due to bioluminescent organisms.\",\n",
    "        \"Things to do\": [\"Take a night kayak tour\", \"Swim in the glowing waters\", \"Learn about the science behind bioluminescence.\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to display destination information\n",
    "def display_destination(destination):\n",
    "    print(\"Destination: \" + destination)\n",
    "    print(\"Description: \" + puerto_rico_guide[destination][\"Description\"])\n",
    "    print(\"Things to do:\")\n",
    "    for activity in puerto_rico_guide[destination][\"Things to do\"]:\n",
    "        print(\"- \" + activity)\n",
    "\n",
    "# Main function to ask user for input and display destination information\n",
    "def main():\n",
    "    print(\"Welcome to the Traveler's Guide to Puerto Rico!\")\n",
    "    print(\"Choose a destination to learn more:\")\n",
    "    for destination in puerto_rico_guide:\n",
    "        print(destination)\n",
    "    choice = input(\"Enter the destination you want to learn more about: \")\n",
    "    if choice in puerto_rico_guide:\n",
    "        display_destination(choice)\n",
    "    else:\n",
    "        print(\"Destination not found. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Traveler's Guide to Puerto Rico!\n",
      "Choose a destination to learn more:\n",
      "elmundo_chunked_en_page1_15y\n",
      "elmundo_chunked_en_page1_15years\n",
      "elmundo_chunked_es_page1_15y\n",
      "elmundo_chunked_es_page1_15years\n",
      "elmundo_chunked_es_page1_40y\n",
      "elmundo_chunked_es_page1_40years\n",
      "landm\n",
      "landmarks\n",
      "links to larger datasets\n",
      "municipali\n",
      "municipalities\n",
      "Destination not found. Please try again.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to read destination information from text files\n",
    "def read_destination_info(destination):\n",
    "    file_path = os.path.join('data', destination + '.txt')\n",
    "    with open(file_path, 'r') as file:\n",
    "        description = file.readline().strip()\n",
    "        things_to_do = [line.strip() for line in file.readlines() if line.strip()]\n",
    "    return description, things_to_do\n",
    "\n",
    "# Function to display destination information\n",
    "def display_destination(destination):\n",
    "    description, things_to_do = read_destination_info(destination)\n",
    "    print(\"Destination: \" + destination)\n",
    "    print(\"Description: \" + description)\n",
    "    print(\"Things to do:\")\n",
    "    for activity in things_to_do:\n",
    "        print(\"- \" + activity)\n",
    "\n",
    "# Main function to ask user for input and display destination information\n",
    "def main():\n",
    "    print(\"Welcome to the Traveler's Guide to Puerto Rico!\")\n",
    "    print(\"Choose a destination to learn more:\")\n",
    "\n",
    "    # Get a list of destination folders in the 'data' directory\n",
    "    destination_folders = os.listdir('data')\n",
    "    destinations = [folder[:-4] for folder in destination_folders]  # Remove the '.txt' extension\n",
    "    for destination in destinations:\n",
    "        print(destination)\n",
    "\n",
    "    choice = input(\"Enter the destination you want to learn more about: \")\n",
    "    if choice in destinations:\n",
    "        display_destination(choice)\n",
    "    else:\n",
    "        print(\"Destination not found. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/11.8 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/11.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.8 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.8 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.3/1.5 MB 33.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 5.0/6.3 MB 25.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   -------------------------------------- - 5.2/5.4 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en terminal: python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of .txt files in the 'data' directory:\n",
      "19200103.txt\n",
      "19200110.txt\n",
      "19200117.txt\n",
      "19200124.txt\n",
      "19200131.txt\n",
      "19200207.txt\n",
      "19200214.txt\n",
      "19200221.txt\n",
      "19200228.txt\n",
      "19200306.txt\n",
      "19200313.txt\n",
      "19200327.txt\n",
      "19200403.txt\n",
      "19200410.txt\n",
      "19200417.txt\n",
      "19200424.txt\n",
      "19200501.txt\n",
      "19200508.txt\n",
      "19200522.txt\n",
      "19200529.txt\n",
      "19200605.txt\n",
      "19200612.txt\n",
      "19200619.txt\n",
      "19200626.txt\n",
      "19200703.txt\n",
      "19200710.txt\n",
      "19200717.txt\n",
      "19200724.txt\n",
      "19200731.txt\n",
      "19200807.txt\n",
      "19200814.txt\n",
      "19200821.txt\n",
      "19200828.txt\n",
      "19200904.txt\n",
      "19200911.txt\n",
      "19200918.txt\n",
      "19200925.txt\n",
      "19201002.txt\n",
      "19201009.txt\n",
      "19201016.txt\n",
      "19201023.txt\n",
      "19201030.txt\n",
      "19201106.txt\n",
      "19201113.txt\n",
      "19201120.txt\n",
      "19201204.txt\n",
      "19201211.txt\n",
      "19201218.txt\n",
      "19210108.txt\n",
      "19210115.txt\n",
      "19210122.txt\n",
      "19210129.txt\n",
      "19210205.txt\n",
      "19210212.txt\n",
      "19210219.txt\n",
      "19210226.txt\n",
      "19210305.txt\n",
      "19210312.txt\n",
      "19210319.txt\n",
      "19210326.txt\n",
      "19210402.txt\n",
      "19210409.txt\n",
      "19210416.txt\n",
      "19210423.txt\n",
      "19210430.txt\n",
      "19210507.txt\n",
      "19210521.txt\n",
      "19210528.txt\n",
      "19210604.txt\n",
      "19210611.txt\n",
      "19210618.txt\n",
      "19210625.txt\n",
      "19210702.txt\n",
      "19210709.txt\n",
      "19210716.txt\n",
      "19210723.txt\n",
      "19210730.txt\n",
      "19210806.txt\n",
      "19210813.txt\n",
      "19210820.txt\n",
      "19210827.txt\n",
      "19210903.txt\n",
      "19210910.txt\n",
      "19210917.txt\n",
      "19210924.txt\n",
      "19211001.txt\n",
      "19211008.txt\n",
      "19211015.txt\n",
      "19211022.txt\n",
      "19211029.txt\n",
      "19211105.txt\n",
      "19211112.txt\n",
      "19211119.txt\n",
      "19211126.txt\n",
      "19211203.txt\n",
      "19211210.txt\n",
      "19211217.txt\n",
      "19211224.txt\n",
      "19211231.txt\n",
      "19220107.txt\n",
      "19220114.txt\n",
      "19220121.txt\n",
      "19220128.txt\n",
      "19220204.txt\n",
      "19220211.txt\n",
      "19220218.txt\n",
      "19220225.txt\n",
      "19220304.txt\n",
      "19220311.txt\n",
      "19220318.txt\n",
      "19220325.txt\n",
      "19220401.txt\n",
      "19220408.txt\n",
      "19220415.txt\n",
      "19220422.txt\n",
      "19220429.txt\n",
      "19220506.txt\n",
      "19220513.txt\n",
      "19220520.txt\n",
      "19220527.txt\n",
      "19220603.txt\n",
      "19220610.txt\n",
      "19220617.txt\n",
      "19220624.txt\n",
      "19220701.txt\n",
      "19220708.txt\n",
      "19220715.txt\n",
      "19220722.txt\n",
      "19220729.txt\n",
      "19220805.txt\n",
      "19220812.txt\n",
      "19220819.txt\n",
      "19220826.txt\n",
      "19220902.txt\n",
      "19220909.txt\n",
      "19220916.txt\n",
      "19220923.txt\n",
      "19220930.txt\n",
      "19221007.txt\n",
      "19221014.txt\n",
      "19221021.txt\n",
      "19221028.txt\n",
      "19221104.txt\n",
      "19221111.txt\n",
      "19221118.txt\n",
      "19221125.txt\n",
      "19221202.txt\n",
      "19221209.txt\n",
      "19221216.txt\n",
      "19221223.txt\n",
      "19221230.txt\n",
      "19230106.txt\n",
      "19230113.txt\n",
      "19230120.txt\n",
      "19230127.txt\n",
      "19230203.txt\n",
      "19230210.txt\n",
      "19230217.txt\n",
      "19230224.txt\n",
      "19230303.txt\n",
      "19230310.txt\n",
      "19230317.txt\n",
      "19230324.txt\n",
      "19230331.txt\n",
      "19230407.txt\n",
      "19230414.txt\n",
      "19230421.txt\n",
      "19230428.txt\n",
      "19230505.txt\n",
      "19230512.txt\n",
      "19230519.txt\n",
      "19230526.txt\n",
      "19230602.txt\n",
      "19230609.txt\n",
      "19230616.txt\n",
      "19230623.txt\n",
      "19230630.txt\n",
      "19230707.txt\n",
      "19230714.txt\n",
      "19230721.txt\n",
      "19230728.txt\n",
      "19230804.txt\n",
      "19230811.txt\n",
      "19230818.txt\n",
      "19230825.txt\n",
      "19230901.txt\n",
      "19230908.txt\n",
      "19230915.txt\n",
      "19230922.txt\n",
      "19230929.txt\n",
      "19231006.txt\n",
      "19231013.txt\n",
      "19231020.txt\n",
      "19231027.txt\n",
      "19231103.txt\n",
      "19231110.txt\n",
      "19231117.txt\n",
      "19231124.txt\n",
      "19231201.txt\n",
      "19231208.txt\n",
      "19231215.txt\n",
      "19231222.txt\n",
      "19231229.txt\n",
      "19240105.txt\n",
      "19240112.txt\n",
      "19240119.txt\n",
      "19240126.txt\n",
      "19240202.txt\n",
      "19240209.txt\n",
      "19240216.txt\n",
      "19240223.txt\n",
      "19240301.txt\n",
      "19240308.txt\n",
      "19240315.txt\n",
      "19240322.txt\n",
      "19240329.txt\n",
      "19240405.txt\n",
      "19240412.txt\n",
      "19240419.txt\n",
      "19240426.txt\n",
      "19240503.txt\n",
      "19240510.txt\n",
      "19240517.txt\n",
      "19240524.txt\n",
      "19240531.txt\n",
      "19240607.txt\n",
      "19240614.txt\n",
      "19240621.txt\n",
      "19240628.txt\n",
      "19240705.txt\n",
      "19240712.txt\n",
      "19240719.txt\n",
      "19240726.txt\n",
      "19240802.txt\n",
      "19240809.txt\n",
      "19240816.txt\n",
      "19240823.txt\n",
      "19240830.txt\n",
      "19240906.txt\n",
      "19240913.txt\n",
      "19240920.txt\n",
      "19240927.txt\n",
      "19241004.txt\n",
      "19241011.txt\n",
      "19241018.txt\n",
      "19241025.txt\n",
      "19241101.txt\n",
      "19241108.txt\n",
      "19241115.txt\n",
      "19241122.txt\n",
      "19241129.txt\n",
      "19241206.txt\n",
      "19241213.txt\n",
      "19241220.txt\n",
      "19241227.txt\n",
      "19250103.txt\n",
      "19250110.txt\n",
      "19250117.txt\n",
      "19250124.txt\n",
      "19250131.txt\n",
      "19250207.txt\n",
      "19250214.txt\n",
      "19250221.txt\n",
      "19250228.txt\n",
      "19250307.txt\n",
      "19250314.txt\n",
      "19250321.txt\n",
      "19250328.txt\n",
      "19250404.txt\n",
      "19250411.txt\n",
      "19250418.txt\n",
      "19250425.txt\n",
      "19250502.txt\n",
      "19250509.txt\n",
      "19250516.txt\n",
      "19250523.txt\n",
      "19250530.txt\n",
      "19250606.txt\n",
      "19250613.txt\n",
      "19250620.txt\n",
      "19250627.txt\n",
      "19250711.txt\n",
      "19250718.txt\n",
      "19250725.txt\n",
      "19250801.txt\n",
      "19250808.txt\n",
      "19250815.txt\n",
      "19250822.txt\n",
      "19250829.txt\n",
      "19250905.txt\n",
      "19250912.txt\n",
      "19250919.txt\n",
      "19250926.txt\n",
      "19251003.txt\n",
      "19251010.txt\n",
      "19251017.txt\n",
      "19251024.txt\n",
      "19251031.txt\n",
      "19251107.txt\n",
      "19251114.txt\n",
      "19251121.txt\n",
      "19251128.txt\n",
      "19251205.txt\n",
      "19251212.txt\n",
      "19251219.txt\n",
      "19251226.txt\n",
      "19260102.txt\n",
      "19260109.txt\n",
      "19260116.txt\n",
      "19260123.txt\n",
      "19260130.txt\n",
      "19260206.txt\n",
      "19260213.txt\n",
      "19260220.txt\n",
      "19260227.txt\n",
      "19260306.txt\n",
      "19260313.txt\n",
      "19260320.txt\n",
      "19260327.txt\n",
      "19260410.txt\n",
      "19260417.txt\n",
      "19260424.txt\n",
      "19260501.txt\n",
      "19260508.txt\n",
      "19260515.txt\n",
      "19260522.txt\n",
      "19260529.txt\n",
      "19260605.txt\n",
      "19260612.txt\n",
      "19260619.txt\n",
      "19260626.txt\n",
      "19260703.txt\n",
      "19260710.txt\n",
      "19260717.txt\n",
      "19260724.txt\n",
      "19260731.txt\n",
      "19260807.txt\n",
      "19260814.txt\n",
      "19260821.txt\n",
      "19260828.txt\n",
      "19260904.txt\n",
      "19260911.txt\n",
      "19260918.txt\n",
      "19260925.txt\n",
      "19261002.txt\n",
      "19261009.txt\n",
      "19261016.txt\n",
      "19261023.txt\n",
      "19261030.txt\n",
      "19261106.txt\n",
      "19261113.txt\n",
      "19261120.txt\n",
      "19261127.txt\n",
      "19261204.txt\n",
      "19261211.txt\n",
      "19261218.txt\n",
      "19270108.txt\n",
      "19270115.txt\n",
      "19270122.txt\n",
      "19270129.txt\n",
      "19270205.txt\n",
      "19270212.txt\n",
      "19270219.txt\n",
      "19270226.txt\n",
      "19270305.txt\n",
      "19270312.txt\n",
      "19270319.txt\n",
      "19270326.txt\n",
      "19270402.txt\n",
      "19270409.txt\n",
      "19270416.txt\n",
      "19270423.txt\n",
      "19270430.txt\n",
      "19270507.txt\n",
      "19270514.txt\n",
      "19270521.txt\n",
      "19270528.txt\n",
      "19270604.txt\n",
      "19270611.txt\n",
      "19270618.txt\n",
      "19270625.txt\n",
      "19270702.txt\n",
      "19270709.txt\n",
      "19270716.txt\n",
      "19270723.txt\n",
      "19270730.txt\n",
      "19270806.txt\n",
      "19270813.txt\n",
      "19270820.txt\n",
      "19270827.txt\n",
      "19270903.txt\n",
      "19270910.txt\n",
      "19270917.txt\n",
      "19270924.txt\n",
      "19271001.txt\n",
      "19271008.txt\n",
      "19271015.txt\n",
      "19271022.txt\n",
      "19271029.txt\n",
      "19271105.txt\n",
      "19271112.txt\n",
      "19271119.txt\n",
      "19271126.txt\n",
      "19271203.txt\n",
      "19271210.txt\n",
      "19271217.txt\n",
      "19271224.txt\n",
      "19271231.txt\n",
      "19280107.txt\n",
      "19280114.txt\n",
      "19280121.txt\n",
      "19280128.txt\n",
      "19280204.txt\n",
      "19280211.txt\n",
      "19280218.txt\n",
      "19280225.txt\n",
      "19280303.txt\n",
      "19280310.txt\n",
      "19280317.txt\n",
      "19280324.txt\n",
      "19280331.txt\n",
      "19280407.txt\n",
      "19280414.txt\n",
      "19280421.txt\n",
      "19280428.txt\n",
      "19280505.txt\n",
      "19280512.txt\n",
      "19280519.txt\n",
      "19280526.txt\n",
      "19280602.txt\n",
      "19280609.txt\n",
      "19280616.txt\n",
      "19280623.txt\n",
      "19280630.txt\n",
      "19280707.txt\n",
      "19280714.txt\n",
      "19280721.txt\n",
      "19280728.txt\n",
      "19280804.txt\n",
      "19280811.txt\n",
      "19280818.txt\n",
      "19280825.txt\n",
      "19280901.txt\n",
      "19280908.txt\n",
      "19280922.txt\n",
      "19280929.txt\n",
      "19281006.txt\n",
      "19281013.txt\n",
      "19281020.txt\n",
      "19281027.txt\n",
      "19281103.txt\n",
      "19281110.txt\n",
      "19281117.txt\n",
      "19281124.txt\n",
      "19281201.txt\n",
      "19281208.txt\n",
      "19281215.txt\n",
      "19281222.txt\n",
      "19281229.txt\n",
      "19290105.txt\n",
      "19290112.txt\n",
      "19290119.txt\n",
      "19290126.txt\n",
      "19290202.txt\n",
      "19290209.txt\n",
      "19290216.txt\n",
      "19290223.txt\n",
      "19290302.txt\n",
      "19290309.txt\n",
      "19290316.txt\n",
      "19290323.txt\n",
      "19290330.txt\n",
      "19290406.txt\n",
      "19290413.txt\n",
      "19290420.txt\n",
      "19290427.txt\n",
      "19290504.txt\n",
      "19290511.txt\n",
      "19290518.txt\n",
      "19290525.txt\n",
      "19290601.txt\n",
      "19290608.txt\n",
      "19290615.txt\n",
      "19290622.txt\n",
      "19290629.txt\n",
      "19290706.txt\n",
      "19290713.txt\n",
      "19290720.txt\n",
      "19290727.txt\n",
      "19290803.txt\n",
      "19290810.txt\n",
      "19290817.txt\n",
      "19290824.txt\n",
      "19290831.txt\n",
      "19290907.txt\n",
      "19290914.txt\n",
      "19290921.txt\n",
      "19290928.txt\n",
      "19291005.txt\n",
      "19291019.txt\n",
      "19291026.txt\n",
      "19291102.txt\n",
      "19291109.txt\n",
      "19291116.txt\n",
      "19291123.txt\n",
      "19291130.txt\n",
      "19291207.txt\n",
      "19291214.txt\n",
      "19291221.txt\n",
      "19291228.txt\n",
      "19450106.txt\n",
      "19450113.txt\n",
      "19450120.txt\n",
      "19450127.txt\n",
      "19450203.txt\n",
      "19450210.txt\n",
      "19450217.txt\n",
      "19450224.txt\n",
      "19450303.txt\n",
      "19450310.txt\n",
      "19450317.txt\n",
      "19450324.txt\n",
      "19450331.txt\n",
      "19450407.txt\n",
      "19450414.txt\n",
      "19450421.txt\n",
      "19450428.txt\n",
      "19450505.txt\n",
      "19450512.txt\n",
      "19450519.txt\n",
      "19450526.txt\n",
      "19450602.txt\n",
      "19450609.txt\n",
      "19450616.txt\n",
      "19450623.txt\n",
      "19450630.txt\n",
      "19450707.txt\n",
      "19450714.txt\n",
      "19450721.txt\n",
      "19450728.txt\n",
      "19450804.txt\n",
      "19450811.txt\n",
      "19450818.txt\n",
      "19450825.txt\n",
      "19450901.txt\n",
      "19450908.txt\n",
      "19450915.txt\n",
      "19450922.txt\n",
      "19450929.txt\n",
      "19451006.txt\n",
      "19451013.txt\n",
      "19451020.txt\n",
      "19451027.txt\n",
      "19451103.txt\n",
      "19451110.txt\n",
      "19451117.txt\n",
      "19451124.txt\n",
      "19451201.txt\n",
      "19451208.txt\n",
      "19451215.txt\n",
      "19451222.txt\n",
      "19451229.txt\n",
      "19460105.txt\n",
      "19460112.txt\n",
      "19460119.txt\n",
      "19460126.txt\n",
      "19460202.txt\n",
      "19460209.txt\n",
      "19460216.txt\n",
      "19460223.txt\n",
      "19460302.txt\n",
      "19460309.txt\n",
      "19460316.txt\n",
      "19460323.txt\n",
      "19460330.txt\n",
      "19460406.txt\n",
      "19460413.txt\n",
      "19460420.txt\n",
      "19460427.txt\n",
      "19460504.txt\n",
      "19460511.txt\n",
      "19460518.txt\n",
      "19460525.txt\n",
      "19460601.txt\n",
      "19460608.txt\n",
      "19460615.txt\n",
      "19460622.txt\n",
      "19460629.txt\n",
      "19460706.txt\n",
      "19460713.txt\n",
      "19460720.txt\n",
      "19460727.txt\n",
      "19460803.txt\n",
      "19460810.txt\n",
      "19460817.txt\n",
      "19460824.txt\n",
      "19460831.txt\n",
      "19460907.txt\n",
      "19460914.txt\n",
      "19460921.txt\n",
      "19460928.txt\n",
      "19461005.txt\n",
      "19461012.txt\n",
      "19461019.txt\n",
      "19461026.txt\n",
      "19461102.txt\n",
      "19461109.txt\n",
      "19461116.txt\n",
      "19461123.txt\n",
      "19461130.txt\n",
      "19461207.txt\n",
      "19461214.txt\n",
      "19461221.txt\n",
      "19461228.txt\n",
      "19470104.txt\n",
      "19470111.txt\n",
      "19470118.txt\n",
      "19470125.txt\n",
      "19470201.txt\n",
      "19470208.txt\n",
      "19470215.txt\n",
      "19470222.txt\n",
      "19470301.txt\n",
      "19470308.txt\n",
      "19470315.txt\n",
      "19470322.txt\n",
      "19470329.txt\n",
      "19470405.txt\n",
      "19470412.txt\n",
      "19470419.txt\n",
      "19470426.txt\n",
      "19470503.txt\n",
      "19470510.txt\n",
      "19470517.txt\n",
      "19470524.txt\n",
      "19470531.txt\n",
      "19470607.txt\n",
      "19470614.txt\n",
      "19470621.txt\n",
      "19470628.txt\n",
      "19470705.txt\n",
      "19470712.txt\n",
      "19470719.txt\n",
      "19470726.txt\n",
      "19470802.txt\n",
      "19470809.txt\n",
      "19470816.txt\n",
      "19470823.txt\n",
      "19470830.txt\n",
      "19470906.txt\n",
      "19470913.txt\n",
      "19470920.txt\n",
      "19470927.txt\n",
      "19471004.txt\n",
      "19471011.txt\n",
      "19471018.txt\n",
      "19471025.txt\n",
      "19471101.txt\n",
      "19471108.txt\n",
      "19471115.txt\n",
      "19471122.txt\n",
      "19471129.txt\n",
      "19471206.txt\n",
      "19471213.txt\n",
      "19471220.txt\n",
      "19471227.txt\n",
      "19480103.txt\n",
      "19480110.txt\n",
      "19480117.txt\n",
      "19480124.txt\n",
      "19480131.txt\n",
      "19480207.txt\n",
      "19480214.txt\n",
      "19480221.txt\n",
      "19480228.txt\n",
      "19480306.txt\n",
      "19480313.txt\n",
      "19480320.txt\n",
      "19480327.txt\n",
      "19480403.txt\n",
      "19480410.txt\n",
      "19480417.txt\n",
      "19480424.txt\n",
      "19480501.txt\n",
      "19480508.txt\n",
      "19480515.txt\n",
      "19480522.txt\n",
      "19480529.txt\n",
      "19480605.txt\n",
      "19480612.txt\n",
      "19480619.txt\n",
      "19480626.txt\n",
      "19480703.txt\n",
      "19480710.txt\n",
      "19480717.txt\n",
      "19480724.txt\n",
      "19480731.txt\n",
      "19480807.txt\n",
      "19480814.txt\n",
      "19480821.txt\n",
      "19480828.txt\n",
      "19480904.txt\n",
      "19480911.txt\n",
      "19480918.txt\n",
      "19480925.txt\n",
      "19481002.txt\n",
      "19481009.txt\n",
      "19481016.txt\n",
      "19481023.txt\n",
      "19481030.txt\n",
      "19481106.txt\n",
      "19481113.txt\n",
      "19481120.txt\n",
      "19481127.txt\n",
      "19481204.txt\n",
      "19481211.txt\n",
      "19481218.txt\n",
      "19490108.txt\n",
      "19490115.txt\n",
      "19490122.txt\n",
      "19490129.txt\n",
      "19490205.txt\n",
      "19490212.txt\n",
      "19490219.txt\n",
      "19490226.txt\n",
      "19490305.txt\n",
      "19490312.txt\n",
      "19490319.txt\n",
      "19490326.txt\n",
      "19490402.txt\n",
      "19490409.txt\n",
      "19490416.txt\n",
      "19490423.txt\n",
      "19490430.txt\n",
      "19490507.txt\n",
      "19490514.txt\n",
      "19490521.txt\n",
      "19490528.txt\n",
      "19490604.txt\n",
      "19490611.txt\n",
      "19490618.txt\n",
      "19490625.txt\n",
      "19490702.txt\n",
      "19490709.txt\n",
      "19490716.txt\n",
      "19490723.txt\n",
      "19490730.txt\n",
      "19490806.txt\n",
      "19490813.txt\n",
      "19490820.txt\n",
      "19490827.txt\n",
      "19490903.txt\n",
      "19490910.txt\n",
      "19490917.txt\n",
      "19490924.txt\n",
      "19491001.txt\n",
      "19491008.txt\n",
      "19491015.txt\n",
      "19491022.txt\n",
      "19491029.txt\n",
      "19491105.txt\n",
      "19491112.txt\n",
      "19491119.txt\n",
      "19491126.txt\n",
      "19491203.txt\n",
      "19491210.txt\n",
      "19491217.txt\n",
      "19491224.txt\n",
      "19491231.txt\n",
      "19500107.txt\n",
      "19500114.txt\n",
      "19500121.txt\n",
      "19500128.txt\n",
      "19500204.txt\n",
      "19500211.txt\n",
      "19500218.txt\n",
      "19500225.txt\n",
      "19500304.txt\n",
      "19500311.txt\n",
      "19500318.txt\n",
      "19500325.txt\n",
      "19500401.txt\n",
      "19500408.txt\n",
      "19500415.txt\n",
      "19500422.txt\n",
      "19500429.txt\n",
      "19500506.txt\n",
      "19500513.txt\n",
      "19500520.txt\n",
      "19500527.txt\n",
      "19500603.txt\n",
      "19500610.txt\n",
      "19500617.txt\n",
      "19500624.txt\n",
      "19500701.txt\n",
      "19500708.txt\n",
      "19500715.txt\n",
      "19500722.txt\n",
      "19500729.txt\n",
      "19500805.txt\n",
      "19500812.txt\n",
      "19500819.txt\n",
      "19500826.txt\n",
      "19500902.txt\n",
      "19500909.txt\n",
      "19500916.txt\n",
      "19500923.txt\n",
      "19500930.txt\n",
      "19501007.txt\n",
      "19501014.txt\n",
      "19501021.txt\n",
      "19501028.txt\n",
      "19501104.txt\n",
      "19501111.txt\n",
      "19501118.txt\n",
      "19501125.txt\n",
      "19501202.txt\n",
      "19501209.txt\n",
      "19501216.txt\n",
      "19501223.txt\n",
      "19501230.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to list .txt files in a directory\n",
    "def list_txt_files(directory):\n",
    "    txt_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')]\n",
    "    return txt_files\n",
    "\n",
    "# Main function to list .txt files in the 'data' directory\n",
    "def main():\n",
    "    data_directory = 'data/elmundo_chunked_es_page1_15years/elmundo_chunked_es_page1_15years'\n",
    "\n",
    "    txt_files = list_txt_files(data_directory)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the 'data' directory:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "    else:\n",
    "        print(\"No .txt files found in the 'data' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# info retrieval from news 15 years el mundo ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm going to Puerto Rico, what are the best places to visit?\n",
      "List of .txt files in the 'data' directory:\n",
      "19200103_1.txt\n",
      "19200110_1.txt\n",
      "19200117_1.txt\n",
      "19200124_1.txt\n",
      "19200131_1.txt\n",
      "19200207_1.txt\n",
      "19200214_1.txt\n",
      "19200221_1.txt\n",
      "19200228_1.txt\n",
      "19200306_1.txt\n",
      "19200313_1.txt\n",
      "19200327_1.txt\n",
      "19200403_1.txt\n",
      "19200410_1.txt\n",
      "19200417_1.txt\n",
      "19200424_1.txt\n",
      "19200501_1.txt\n",
      "19200508_1.txt\n",
      "19200522_1.txt\n",
      "19200529_1.txt\n",
      "19200605_1.txt\n",
      "19200612_1.txt\n",
      "19200619_1.txt\n",
      "19200626_1.txt\n",
      "19200703_1.txt\n",
      "19200710_1.txt\n",
      "19200717_1.txt\n",
      "19200724_1.txt\n",
      "19200731_1.txt\n",
      "19200807_1.txt\n",
      "19200814_1.txt\n",
      "19200821_1.txt\n",
      "19200828_1.txt\n",
      "19200904_1.txt\n",
      "19200911_1.txt\n",
      "19200918_1.txt\n",
      "19200925_1.txt\n",
      "19201002_1.txt\n",
      "19201009_1.txt\n",
      "19201016_1.txt\n",
      "19201023_1.txt\n",
      "19201030_1.txt\n",
      "19201106_1.txt\n",
      "19201113_1.txt\n",
      "19201120_1.txt\n",
      "19201204_1.txt\n",
      "19201211_1.txt\n",
      "19201218_1.txt\n",
      "19210108_1.txt\n",
      "19210115_1.txt\n",
      "19210122_1.txt\n",
      "19210129_1.txt\n",
      "19210205_1.txt\n",
      "19210212_1.txt\n",
      "19210219_1.txt\n",
      "19210226_1.txt\n",
      "19210305_1.txt\n",
      "19210312_1.txt\n",
      "19210319_1.txt\n",
      "19210326_1.txt\n",
      "19210402_1.txt\n",
      "19210409_1.txt\n",
      "19210416_1.txt\n",
      "19210423_1.txt\n",
      "19210430_1.txt\n",
      "19210507_1.txt\n",
      "19210521_1.txt\n",
      "19210528_1.txt\n",
      "19210604_1.txt\n",
      "19210611_1.txt\n",
      "19210618_1.txt\n",
      "19210625_1.txt\n",
      "19210702_1.txt\n",
      "19210709_1.txt\n",
      "19210716_1.txt\n",
      "19210723_1.txt\n",
      "19210730_1.txt\n",
      "19210806_1.txt\n",
      "19210813_1.txt\n",
      "19210820_1.txt\n",
      "19210827_1.txt\n",
      "19210903_1.txt\n",
      "19210910_1.txt\n",
      "19210917_1.txt\n",
      "19210924_1.txt\n",
      "19211001_1.txt\n",
      "19211008_1.txt\n",
      "19211015_1.txt\n",
      "19211022_1.txt\n",
      "19211029_1.txt\n",
      "19211105_1.txt\n",
      "19211112_1.txt\n",
      "19211119_1.txt\n",
      "19211126_1.txt\n",
      "19211203_1.txt\n",
      "19211210_1.txt\n",
      "19211217_1.txt\n",
      "19211224_1.txt\n",
      "19211231_1.txt\n",
      "19220107_1.txt\n",
      "19220114_1.txt\n",
      "19220121_1.txt\n",
      "19220128_1.txt\n",
      "19220204_1.txt\n",
      "19220211_1.txt\n",
      "19220218_1.txt\n",
      "19220225_1.txt\n",
      "19220304_1.txt\n",
      "19220311_1.txt\n",
      "19220318_1.txt\n",
      "19220325_1.txt\n",
      "19220401_1.txt\n",
      "19220408_1.txt\n",
      "19220415_1.txt\n",
      "19220422_1.txt\n",
      "19220429_1.txt\n",
      "19220506_1.txt\n",
      "19220513_1.txt\n",
      "19220520_1.txt\n",
      "19220527_1.txt\n",
      "19220603_1.txt\n",
      "19220610_1.txt\n",
      "19220617_1.txt\n",
      "19220624_1.txt\n",
      "19220701_1.txt\n",
      "19220708_1.txt\n",
      "19220715_1.txt\n",
      "19220722_1.txt\n",
      "19220729_1.txt\n",
      "19220805_1.txt\n",
      "19220812_1.txt\n",
      "19220819_1.txt\n",
      "19220826_1.txt\n",
      "19220902_1.txt\n",
      "19220909_1.txt\n",
      "19220916_1.txt\n",
      "19220923_1.txt\n",
      "19220930_1.txt\n",
      "19221007_1.txt\n",
      "19221014_1.txt\n",
      "19221021_1.txt\n",
      "19221028_1.txt\n",
      "19221104_1.txt\n",
      "19221111_1.txt\n",
      "19221118_1.txt\n",
      "19221125_1.txt\n",
      "19221202_1.txt\n",
      "19221209_1.txt\n",
      "19221216_1.txt\n",
      "19221223_1.txt\n",
      "19221230_1.txt\n",
      "19230106_1.txt\n",
      "19230113_1.txt\n",
      "19230120_1.txt\n",
      "19230127_1.txt\n",
      "19230203_1.txt\n",
      "19230210_1.txt\n",
      "19230217_1.txt\n",
      "19230224_1.txt\n",
      "19230303_1.txt\n",
      "19230310_1.txt\n",
      "19230317_1.txt\n",
      "19230324_1.txt\n",
      "19230331_1.txt\n",
      "19230407_1.txt\n",
      "19230414_1.txt\n",
      "19230421_1.txt\n",
      "19230428_1.txt\n",
      "19230505_1.txt\n",
      "19230512_1.txt\n",
      "19230519_1.txt\n",
      "19230526_1.txt\n",
      "19230602_1.txt\n",
      "19230609_1.txt\n",
      "19230616_1.txt\n",
      "19230623_1.txt\n",
      "19230630_1.txt\n",
      "19230707_1.txt\n",
      "19230714_1.txt\n",
      "19230721_1.txt\n",
      "19230728_1.txt\n",
      "19230804_1.txt\n",
      "19230811_1.txt\n",
      "19230818_1.txt\n",
      "19230825_1.txt\n",
      "19230901_1.txt\n",
      "19230908_1.txt\n",
      "19230915_1.txt\n",
      "19230922_1.txt\n",
      "19230929_1.txt\n",
      "19231006_1.txt\n",
      "19231013_1.txt\n",
      "19231020_1.txt\n",
      "19231027_1.txt\n",
      "19231103_1.txt\n",
      "19231110_1.txt\n",
      "19231117_1.txt\n",
      "19231124_1.txt\n",
      "19231201_1.txt\n",
      "19231208_1.txt\n",
      "19231215_1.txt\n",
      "19231222_1.txt\n",
      "19231229_1.txt\n",
      "19240105_1.txt\n",
      "19240112_1.txt\n",
      "19240119_1.txt\n",
      "19240126_1.txt\n",
      "19240202_1.txt\n",
      "19240209_1.txt\n",
      "19240216_1.txt\n",
      "19240223_1.txt\n",
      "19240301_1.txt\n",
      "19240308_1.txt\n",
      "19240315_1.txt\n",
      "19240322_1.txt\n",
      "19240329_1.txt\n",
      "19240405_1.txt\n",
      "19240412_1.txt\n",
      "19240419_1.txt\n",
      "19240426_1.txt\n",
      "19240503_1.txt\n",
      "19240510_1.txt\n",
      "19240517_1.txt\n",
      "19240524_1.txt\n",
      "19240531_1.txt\n",
      "19240607_1.txt\n",
      "19240614_1.txt\n",
      "19240621_1.txt\n",
      "19240628_1.txt\n",
      "19240705_1.txt\n",
      "19240712_1.txt\n",
      "19240719_1.txt\n",
      "19240726_1.txt\n",
      "19240802_1.txt\n",
      "19240809_1.txt\n",
      "19240816_1.txt\n",
      "19240823_1.txt\n",
      "19240830_1.txt\n",
      "19240906_1.txt\n",
      "19240913_1.txt\n",
      "19240920_1.txt\n",
      "19240927_1.txt\n",
      "19241004_1.txt\n",
      "19241011_1.txt\n",
      "19241018_1.txt\n",
      "19241025_1.txt\n",
      "19241101_1.txt\n",
      "19241108_1.txt\n",
      "19241115_1.txt\n",
      "19241122_1.txt\n",
      "19241129_1.txt\n",
      "19241206_1.txt\n",
      "19241213_1.txt\n",
      "19241220_1.txt\n",
      "19241227_1.txt\n",
      "19250103_1.txt\n",
      "19250110_1.txt\n",
      "19250117_1.txt\n",
      "19250124_1.txt\n",
      "19250131_1.txt\n",
      "19250207_1.txt\n",
      "19250214_1.txt\n",
      "19250221_1.txt\n",
      "19250228_1.txt\n",
      "19250307_1.txt\n",
      "19250314_1.txt\n",
      "19250321_1.txt\n",
      "19250328_1.txt\n",
      "19250404_1.txt\n",
      "19250411_1.txt\n",
      "19250418_1.txt\n",
      "19250425_1.txt\n",
      "19250502_1.txt\n",
      "19250509_1.txt\n",
      "19250516_1.txt\n",
      "19250523_1.txt\n",
      "19250530_1.txt\n",
      "19250606_1.txt\n",
      "19250613_1.txt\n",
      "19250620_1.txt\n",
      "19250627_1.txt\n",
      "19250711_1.txt\n",
      "19250718_1.txt\n",
      "19250725_1.txt\n",
      "19250801_1.txt\n",
      "19250808_1.txt\n",
      "19250815_1.txt\n",
      "19250822_1.txt\n",
      "19250829_1.txt\n",
      "19250905_1.txt\n",
      "19250912_1.txt\n",
      "19250919_1.txt\n",
      "19250926_1.txt\n",
      "19251003_1.txt\n",
      "19251010_1.txt\n",
      "19251017_1.txt\n",
      "19251024_1.txt\n",
      "19251031_1.txt\n",
      "19251107_1.txt\n",
      "19251114_1.txt\n",
      "19251121_1.txt\n",
      "19251128_1.txt\n",
      "19251205_1.txt\n",
      "19251212_1.txt\n",
      "19251219_1.txt\n",
      "19251226_1.txt\n",
      "19260102_1.txt\n",
      "19260109_1.txt\n",
      "19260116_1.txt\n",
      "19260123_1.txt\n",
      "19260130_1.txt\n",
      "19260206_1.txt\n",
      "19260213_1.txt\n",
      "19260220_1.txt\n",
      "19260227_1.txt\n",
      "19260306_1.txt\n",
      "19260313_1.txt\n",
      "19260320_1.txt\n",
      "19260327_1.txt\n",
      "19260410_1.txt\n",
      "19260417_1.txt\n",
      "19260424_1.txt\n",
      "19260501_1.txt\n",
      "19260508_1.txt\n",
      "19260515_1.txt\n",
      "19260522_1.txt\n",
      "19260529_1.txt\n",
      "19260605_1.txt\n",
      "19260612_1.txt\n",
      "19260619_1.txt\n",
      "19260626_1.txt\n",
      "19260703_1.txt\n",
      "19260710_1.txt\n",
      "19260717_1.txt\n",
      "19260724_1.txt\n",
      "19260731_1.txt\n",
      "19260807_1.txt\n",
      "19260814_1.txt\n",
      "19260821_1.txt\n",
      "19260828_1.txt\n",
      "19260904_1.txt\n",
      "19260911_1.txt\n",
      "19260918_1.txt\n",
      "19260925_1.txt\n",
      "19261002_1.txt\n",
      "19261009_1.txt\n",
      "19261016_1.txt\n",
      "19261023_1.txt\n",
      "19261030_1.txt\n",
      "19261106_1.txt\n",
      "19261113_1.txt\n",
      "19261120_1.txt\n",
      "19261127_1.txt\n",
      "19261204_1.txt\n",
      "19261211_1.txt\n",
      "19261218_1.txt\n",
      "19270108_1.txt\n",
      "19270115_1.txt\n",
      "19270122_1.txt\n",
      "19270129_1.txt\n",
      "19270205_1.txt\n",
      "19270212_1.txt\n",
      "19270219_1.txt\n",
      "19270226_1.txt\n",
      "19270305_1.txt\n",
      "19270312_1.txt\n",
      "19270319_1.txt\n",
      "19270326_1.txt\n",
      "19270402_1.txt\n",
      "19270409_1.txt\n",
      "19270416_1.txt\n",
      "19270423_1.txt\n",
      "19270430_1.txt\n",
      "19270507_1.txt\n",
      "19270514_1.txt\n",
      "19270521_1.txt\n",
      "19270528_1.txt\n",
      "19270604_1.txt\n",
      "19270611_1.txt\n",
      "19270618_1.txt\n",
      "19270625_1.txt\n",
      "19270702_1.txt\n",
      "19270709_1.txt\n",
      "19270716_1.txt\n",
      "19270723_1.txt\n",
      "19270730_1.txt\n",
      "19270806_1.txt\n",
      "19270813_1.txt\n",
      "19270820_1.txt\n",
      "19270827_1.txt\n",
      "19270903_1.txt\n",
      "19270910_1.txt\n",
      "19270917_1.txt\n",
      "19270924_1.txt\n",
      "19271001_1.txt\n",
      "19271008_1.txt\n",
      "19271015_1.txt\n",
      "19271022_1.txt\n",
      "19271029_1.txt\n",
      "19271105_1.txt\n",
      "19271112_1.txt\n",
      "19271119_1.txt\n",
      "19271126_1.txt\n",
      "19271203_1.txt\n",
      "19271210_1.txt\n",
      "19271217_1.txt\n",
      "19271224_1.txt\n",
      "19271231_1.txt\n",
      "19280107_1.txt\n",
      "19280114_1.txt\n",
      "19280121_1.txt\n",
      "19280128_1.txt\n",
      "19280204_1.txt\n",
      "19280211_1.txt\n",
      "19280218_1.txt\n",
      "19280225_1.txt\n",
      "19280303_1.txt\n",
      "19280310_1.txt\n",
      "19280317_1.txt\n",
      "19280324_1.txt\n",
      "19280331_1.txt\n",
      "19280407_1.txt\n",
      "19280414_1.txt\n",
      "19280421_1.txt\n",
      "19280428_1.txt\n",
      "19280505_1.txt\n",
      "19280512_1.txt\n",
      "19280519_1.txt\n",
      "19280526_1.txt\n",
      "19280602_1.txt\n",
      "19280609_1.txt\n",
      "19280616_1.txt\n",
      "19280623_1.txt\n",
      "19280630_1.txt\n",
      "19280707_1.txt\n",
      "19280714_1.txt\n",
      "19280721_1.txt\n",
      "19280728_1.txt\n",
      "19280804_1.txt\n",
      "19280811_1.txt\n",
      "19280818_1.txt\n",
      "19280825_1.txt\n",
      "19280901_1.txt\n",
      "19280908_1.txt\n",
      "19280922_1.txt\n",
      "19280929_1.txt\n",
      "19281006_1.txt\n",
      "19281013_1.txt\n",
      "19281020_1.txt\n",
      "19281027_1.txt\n",
      "19281103_1.txt\n",
      "19281110_1.txt\n",
      "19281117_1.txt\n",
      "19281124_1.txt\n",
      "19281201_1.txt\n",
      "19281208_1.txt\n",
      "19281215_1.txt\n",
      "19281222_1.txt\n",
      "19281229_1.txt\n",
      "19290105_1.txt\n",
      "19290112_1.txt\n",
      "19290119_1.txt\n",
      "19290126_1.txt\n",
      "19290202_1.txt\n",
      "19290209_1.txt\n",
      "19290216_1.txt\n",
      "19290223_1.txt\n",
      "19290302_1.txt\n",
      "19290309_1.txt\n",
      "19290316_1.txt\n",
      "19290323_1.txt\n",
      "19290330_1.txt\n",
      "19290406_1.txt\n",
      "19290413_1.txt\n",
      "19290420_1.txt\n",
      "19290427_1.txt\n",
      "19290504_1.txt\n",
      "19290511_1.txt\n",
      "19290518_1.txt\n",
      "19290525_1.txt\n",
      "19290601_1.txt\n",
      "19290608_1.txt\n",
      "19290615_1.txt\n",
      "19290622_1.txt\n",
      "19290629_1.txt\n",
      "19290706_1.txt\n",
      "19290713_1.txt\n",
      "19290720_1.txt\n",
      "19290727_1.txt\n",
      "19290803_1.txt\n",
      "19290810_1.txt\n",
      "19290817_1.txt\n",
      "19290824_1.txt\n",
      "19290831_1.txt\n",
      "19290907_1.txt\n",
      "19290914_1.txt\n",
      "19290921_1.txt\n",
      "19290928_1.txt\n",
      "19291005_1.txt\n",
      "19291019_1.txt\n",
      "19291026_1.txt\n",
      "19291102_1.txt\n",
      "19291109_1.txt\n",
      "19291116_1.txt\n",
      "19291123_1.txt\n",
      "19291130_1.txt\n",
      "19291207_1.txt\n",
      "19291214_1.txt\n",
      "19291221_1.txt\n",
      "19291228_1.txt\n",
      "19450106_1.txt\n",
      "19450113_1.txt\n",
      "19450120_1.txt\n",
      "19450127_1.txt\n",
      "19450203_1.txt\n",
      "19450210_1.txt\n",
      "19450217_1.txt\n",
      "19450224_1.txt\n",
      "19450303_1.txt\n",
      "19450310_1.txt\n",
      "19450317_1.txt\n",
      "19450324_1.txt\n",
      "19450331_1.txt\n",
      "19450407_1.txt\n",
      "19450414_1.txt\n",
      "19450421_1.txt\n",
      "19450428_1.txt\n",
      "19450505_1.txt\n",
      "19450512_1.txt\n",
      "19450519_1.txt\n",
      "19450526_1.txt\n",
      "19450602_1.txt\n",
      "19450609_1.txt\n",
      "19450616_1.txt\n",
      "19450623_1.txt\n",
      "19450630_1.txt\n",
      "19450707_1.txt\n",
      "19450714_1.txt\n",
      "19450721_1.txt\n",
      "19450728_1.txt\n",
      "19450804_1.txt\n",
      "19450811_1.txt\n",
      "19450818_1.txt\n",
      "19450825_1.txt\n",
      "19450901_1.txt\n",
      "19450908_1.txt\n",
      "19450915_1.txt\n",
      "19450922_1.txt\n",
      "19450929_1.txt\n",
      "19451006_1.txt\n",
      "19451013_1.txt\n",
      "19451020_1.txt\n",
      "19451027_1.txt\n",
      "19451103_1.txt\n",
      "19451110_1.txt\n",
      "19451117_1.txt\n",
      "19451124_1.txt\n",
      "19451201_1.txt\n",
      "19451208_1.txt\n",
      "19451215_1.txt\n",
      "19451222_1.txt\n",
      "19451229_1.txt\n",
      "19460105_1.txt\n",
      "19460112_1.txt\n",
      "19460119_1.txt\n",
      "19460126_1.txt\n",
      "19460202_1.txt\n",
      "19460209_1.txt\n",
      "19460216_1.txt\n",
      "19460223_1.txt\n",
      "19460302_1.txt\n",
      "19460309_1.txt\n",
      "19460316_1.txt\n",
      "19460323_1.txt\n",
      "19460330_1.txt\n",
      "19460406_1.txt\n",
      "19460413_1.txt\n",
      "19460420_1.txt\n",
      "19460427_1.txt\n",
      "19460504_1.txt\n",
      "19460511_1.txt\n",
      "19460518_1.txt\n",
      "19460525_1.txt\n",
      "19460601_1.txt\n",
      "19460608_1.txt\n",
      "19460615_1.txt\n",
      "19460622_1.txt\n",
      "19460629_1.txt\n",
      "19460706_1.txt\n",
      "19460713_1.txt\n",
      "19460720_1.txt\n",
      "19460727_1.txt\n",
      "19460803_1.txt\n",
      "19460810_1.txt\n",
      "19460817_1.txt\n",
      "19460824_1.txt\n",
      "19460831_1.txt\n",
      "19460907_1.txt\n",
      "19460914_1.txt\n",
      "19460921_1.txt\n",
      "19460928_1.txt\n",
      "19461005_1.txt\n",
      "19461012_1.txt\n",
      "19461019_1.txt\n",
      "19461026_1.txt\n",
      "19461102_1.txt\n",
      "19461109_1.txt\n",
      "19461116_1.txt\n",
      "19461123_1.txt\n",
      "19461130_1.txt\n",
      "19461207_1.txt\n",
      "19461214_1.txt\n",
      "19461221_1.txt\n",
      "19461228_1.txt\n",
      "19470104_1.txt\n",
      "19470111_1.txt\n",
      "19470118_1.txt\n",
      "19470125_1.txt\n",
      "19470201_1.txt\n",
      "19470208_1.txt\n",
      "19470215_1.txt\n",
      "19470222_1.txt\n",
      "19470301_1.txt\n",
      "19470308_1.txt\n",
      "19470315_1.txt\n",
      "19470322_1.txt\n",
      "19470329_1.txt\n",
      "19470405_1.txt\n",
      "19470412_1.txt\n",
      "19470419_1.txt\n",
      "19470426_1.txt\n",
      "19470503_1.txt\n",
      "19470510_1.txt\n",
      "19470517_1.txt\n",
      "19470524_1.txt\n",
      "19470531_1.txt\n",
      "19470607_1.txt\n",
      "19470614_1.txt\n",
      "19470621_1.txt\n",
      "19470628_1.txt\n",
      "19470705_1.txt\n",
      "19470712_1.txt\n",
      "19470719_1.txt\n",
      "19470726_1.txt\n",
      "19470802_1.txt\n",
      "19470809_1.txt\n",
      "19470816_1.txt\n",
      "19470823_1.txt\n",
      "19470830_1.txt\n",
      "19470906_1.txt\n",
      "19470913_1.txt\n",
      "19470920_1.txt\n",
      "19470927_1.txt\n",
      "19471004_1.txt\n",
      "19471011_1.txt\n",
      "19471018_1.txt\n",
      "19471025_1.txt\n",
      "19471101_1.txt\n",
      "19471108_1.txt\n",
      "19471115_1.txt\n",
      "19471122_1.txt\n",
      "19471129_1.txt\n",
      "19471206_1.txt\n",
      "19471213_1.txt\n",
      "19471220_1.txt\n",
      "19471227_1.txt\n",
      "19480103_1.txt\n",
      "19480110_1.txt\n",
      "19480117_1.txt\n",
      "19480124_1.txt\n",
      "19480131_1.txt\n",
      "19480207_1.txt\n",
      "19480214_1.txt\n",
      "19480221_1.txt\n",
      "19480228_1.txt\n",
      "19480306_1.txt\n",
      "19480313_1.txt\n",
      "19480320_1.txt\n",
      "19480327_1.txt\n",
      "19480403_1.txt\n",
      "19480410_1.txt\n",
      "19480417_1.txt\n",
      "19480424_1.txt\n",
      "19480501_1.txt\n",
      "19480508_1.txt\n",
      "19480515_1.txt\n",
      "19480522_1.txt\n",
      "19480529_1.txt\n",
      "19480605_1.txt\n",
      "19480612_1.txt\n",
      "19480619_1.txt\n",
      "19480626_1.txt\n",
      "19480703_1.txt\n",
      "19480710_1.txt\n",
      "19480717_1.txt\n",
      "19480724_1.txt\n",
      "19480731_1.txt\n",
      "19480807_1.txt\n",
      "19480814_1.txt\n",
      "19480821_1.txt\n",
      "19480828_1.txt\n",
      "19480904_1.txt\n",
      "19480911_1.txt\n",
      "19480918_1.txt\n",
      "19480925_1.txt\n",
      "19481002_1.txt\n",
      "19481009_1.txt\n",
      "19481016_1.txt\n",
      "19481023_1.txt\n",
      "19481030_1.txt\n",
      "19481106_1.txt\n",
      "19481113_1.txt\n",
      "19481120_1.txt\n",
      "19481127_1.txt\n",
      "19481204_1.txt\n",
      "19481211_1.txt\n",
      "19481218_1.txt\n",
      "19490108_1.txt\n",
      "19490115_1.txt\n",
      "19490122_1.txt\n",
      "19490129_1.txt\n",
      "19490205_1.txt\n",
      "19490212_1.txt\n",
      "19490219_1.txt\n",
      "19490226_1.txt\n",
      "19490305_1.txt\n",
      "19490312_1.txt\n",
      "19490319_1.txt\n",
      "19490326_1.txt\n",
      "19490402_1.txt\n",
      "19490409_1.txt\n",
      "19490416_1.txt\n",
      "19490423_1.txt\n",
      "19490430_1.txt\n",
      "19490507_1.txt\n",
      "19490514_1.txt\n",
      "19490521_1.txt\n",
      "19490528_1.txt\n",
      "19490604_1.txt\n",
      "19490611_1.txt\n",
      "19490618_1.txt\n",
      "19490625_1.txt\n",
      "19490702_1.txt\n",
      "19490709_1.txt\n",
      "19490716_1.txt\n",
      "19490723_1.txt\n",
      "19490730_1.txt\n",
      "19490806_1.txt\n",
      "19490813_1.txt\n",
      "19490820_1.txt\n",
      "19490827_1.txt\n",
      "19490903_1.txt\n",
      "19490910_1.txt\n",
      "19490917_1.txt\n",
      "19490924_1.txt\n",
      "19491001_1.txt\n",
      "19491008_1.txt\n",
      "19491015_1.txt\n",
      "19491022_1.txt\n",
      "19491029_1.txt\n",
      "19491105_1.txt\n",
      "19491112_1.txt\n",
      "19491119_1.txt\n",
      "19491126_1.txt\n",
      "19491203_1.txt\n",
      "19491210_1.txt\n",
      "19491217_1.txt\n",
      "19491224_1.txt\n",
      "19491231_1.txt\n",
      "19500107_1.txt\n",
      "19500114_1.txt\n",
      "19500121_1.txt\n",
      "19500128_1.txt\n",
      "19500204_1.txt\n",
      "19500211_1.txt\n",
      "19500218_1.txt\n",
      "19500225_1.txt\n",
      "19500304_1.txt\n",
      "19500311_1.txt\n",
      "19500318_1.txt\n",
      "19500325_1.txt\n",
      "19500401_1.txt\n",
      "19500408_1.txt\n",
      "19500415_1.txt\n",
      "19500422_1.txt\n",
      "19500429_1.txt\n",
      "19500506_1.txt\n",
      "19500513_1.txt\n",
      "19500520_1.txt\n",
      "19500527_1.txt\n",
      "19500603_1.txt\n",
      "19500610_1.txt\n",
      "19500617_1.txt\n",
      "19500624_1.txt\n",
      "19500701_1.txt\n",
      "19500708_1.txt\n",
      "19500715_1.txt\n",
      "19500722_1.txt\n",
      "19500729_1.txt\n",
      "19500805_1.txt\n",
      "19500812_1.txt\n",
      "19500819_1.txt\n",
      "19500826_1.txt\n",
      "19500902_1.txt\n",
      "19500909_1.txt\n",
      "19500916_1.txt\n",
      "19500923_1.txt\n",
      "19500930_1.txt\n",
      "19501007_1.txt\n",
      "19501014_1.txt\n",
      "19501021_1.txt\n",
      "19501028_1.txt\n",
      "19501104_1.txt\n",
      "19501111_1.txt\n",
      "19501118_1.txt\n",
      "19501125_1.txt\n",
      "19501202_1.txt\n",
      "19501209_1.txt\n",
      "19501216_1.txt\n",
      "19501223_1.txt\n",
      "19501230_1.txt\n",
      "\n",
      "No relevant information found in the .txt files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to list .txt files in a directory\n",
    "def list_txt_files(directory):\n",
    "    txt_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')]\n",
    "    return txt_files\n",
    "\n",
    "# Function to read text content from a .txt file\n",
    "'''def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()'''\n",
    "# Function to read text content from a .txt file with specified encoding\n",
    "def read_txt_file(file_path, encoding='utf-8'):\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        return file.read()\n",
    "\n",
    "# Function to search for relevant information in the .txt files based on a user query\n",
    "def search_text_files(directory, user_query):\n",
    "    relevant_info = []\n",
    "    txt_files = list_txt_files(directory)\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        file_path = os.path.join(directory, txt_file)\n",
    "        text_content = read_txt_file(file_path)\n",
    "        if user_query in text_content:\n",
    "            relevant_info.append(text_content)\n",
    "\n",
    "    return relevant_info\n",
    "\n",
    "# Main function to list .txt files in the 'data' directory and search for information based on user query\n",
    "def main(user_query):\n",
    "    data_directory = 'data/elmundo_chunked_en_page1_15years/elmundo_chunked_en_page1_15years'\n",
    "\n",
    "    txt_files = list_txt_files(data_directory)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the 'data' directory:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "\n",
    "        relevant_info = search_text_files(data_directory, user_query)\n",
    "        if relevant_info:\n",
    "            print(\"\\nRelevant information found in the .txt files:\")\n",
    "            for info in relevant_info:\n",
    "                print(info)\n",
    "        else:\n",
    "            print(\"\\nNo relevant information found in the .txt files.\")\n",
    "    else:\n",
    "        print(\"No .txt files found in the 'data' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    print(user_query)\n",
    "    main(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# info retrieval de landmask y municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puerto rico and cabo rojo\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike or None, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your question: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_query)\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[84], line 34\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(user_query)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m(user_query):\n\u001b[0;32m     32\u001b[0m     data_directory \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/landmarks/landmarks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/municipalities/municipalities\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     txt_files \u001b[38;5;241m=\u001b[39m \u001b[43mlist_txt_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m txt_files:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of .txt files in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[84], line 5\u001b[0m, in \u001b[0;36mlist_txt_files\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_txt_files\u001b[39m(directory):\n\u001b[1;32m----> 5\u001b[0m     txt_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, f)) \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m txt_files\n",
      "\u001b[1;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike or None, not tuple"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to list .txt files in a directory\n",
    "def list_txt_files(directory):\n",
    "    txt_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')]\n",
    "    return txt_files\n",
    "\n",
    "# Function to read text content from a .txt file\n",
    "'''def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()'''\n",
    "# Function to read text content from a .txt file with specified encoding\n",
    "def read_txt_file(file_path, encoding='utf-8'):\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        return file.read()\n",
    "\n",
    "# Function to search for relevant information in the .txt files based on a user query\n",
    "def search_text_files(directory, user_query):\n",
    "    relevant_info = []\n",
    "    txt_files = list_txt_files(directory)\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        file_path = os.path.join(directory, txt_file)\n",
    "        text_content = read_txt_file(file_path)\n",
    "        if user_query in text_content:\n",
    "            relevant_info.append(text_content)\n",
    "\n",
    "    return relevant_info\n",
    "\n",
    "# Main function to list .txt files in the 'data' directory and search for information based on user query\n",
    "def main(user_query):\n",
    "    data_directory = ('data/landmarks/landmarks', 'data/municipalities/municipalities')\n",
    "\n",
    "    txt_files = list_txt_files(data_directory)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the 'data' directory:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "\n",
    "        relevant_info = search_text_files(data_directory, user_query)\n",
    "        if relevant_info:\n",
    "            print(\"\\nRelevant information found in the .txt files:\")\n",
    "            for info in relevant_info:\n",
    "                print(info)\n",
    "        else:\n",
    "            print(\"\\nNo relevant information found in the .txt files.\")\n",
    "    else:\n",
    "        print(\"No .txt files found in the 'data' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    print(user_query)\n",
    "    main(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabo rojo\n",
      "List of .txt files in the specified directories:\n",
      "academia_del_perpetuo_socorro.txt\n",
      "academia_interamericana_metro.txt\n",
      "academia_maria_reina.txt\n",
      "academia_san_jorge.txt\n",
      "adjuntas_barrio-pueblo.txt\n",
      "aguada_barrio-pueblo.txt\n",
      "aguada_transmission_station.txt\n",
      "aguadilla_barrio-pueblo.txt\n",
      "aguadilla_ice_skating_arena.txt\n",
      "aguas_buenas_barrio-pueblo.txt\n",
      "aguas_buenas_cave_system.txt\n",
      "aguirre_state_forest.txt\n",
      "aibonito_barrio-pueblo.txt\n",
      "aibonito_festival_of_flowers.txt\n",
      "albergue_ol√≠mpico.txt\n",
      "albizu_university.txt\n",
      "ana_g._m√©ndez_university.txt\n",
      "antiguo_casino_de_ponce.txt\n",
      "antiguo_cuartel_militar_espa√±ol_de_ponce.txt\n",
      "antiguo_hospital_militar_espa√±ol_de_ponce.txt\n",
      "archivo_general_de_puerto_rico.txt\n",
      "arecibo_barrio-pueblo.txt\n",
      "arecibo_light.txt\n",
      "arecibo_observatory.txt\n",
      "arecibo_telescope.txt\n",
      "arenas_bridge.txt\n",
      "arroyo_barrio-pueblo.txt\n",
      "asilo_de_pobres.txt\n",
      "ateneo_puertorrique√±o.txt\n",
      "auditorio_juan_pach√≠n_vic√©ns.txt\n",
      "a√±asco_barrio-pueblo.txt\n",
      "bacardi.txt\n",
      "bah√≠a_de_jobos.txt\n",
      "ballaj√°_barracks.txt\n",
      "balneario_de_rinc√≥n.txt\n",
      "banco_cr√©dito_y_ahorro_ponce√±o_(building).txt\n",
      "banco_de_ponce_(building).txt\n",
      "barceloneta_barrio-pueblo.txt\n",
      "barranquitas_barrio-pueblo.txt\n",
      "bas√≠lica_menor_de_la_virgen_de_monserrate.txt\n",
      "bayam√≥n_barrio-pueblo.txt\n",
      "bayam√≥n_city_hall.txt\n",
      "bayam√≥n_river.txt\n",
      "ba√±os_de_coamo.txt\n",
      "biblical_magi.txt\n",
      "biblioteca_carnegie.txt\n",
      "biblioteca_municipal_de_ponce.txt\n",
      "birth_of_the_new_world.txt\n",
      "black_sand.txt\n",
      "blue_beach_(vieques).txt\n",
      "bobbin_lace.txt\n",
      "bolera_caribe.txt\n",
      "boquer√≥n,_cabo_rojo,_puerto_rico.txt\n",
      "boquer√≥n_state_forest.txt\n",
      "braulio_castillo.txt\n",
      "buy√©_beach.txt\n",
      "cabo_rojo_barrio-pueblo.txt\n",
      "cabo_rojo_national_wildlife_refuge.txt\n",
      "caf√©_rico.txt\n",
      "caguana_ceremonial_ball_courts_site.txt\n",
      "caguas_barrio-pueblo.txt\n",
      "caguas_city_hall.txt\n",
      "caguas_museum_of_art.txt\n",
      "caguas_museum_of_folk_arts.txt\n",
      "caguas_museum_of_tobacco.txt\n",
      "caguas_valley.txt\n",
      "caja_de_muertos.txt\n",
      "calle_25_de_enero.txt\n",
      "cambalache_forest_reserve.txt\n",
      "campamento_santiago.txt\n",
      "campo_atl√©tico_charles_h._terry.txt\n",
      "camuy_barrio-pueblo.txt\n",
      "camuy_river.txt\n",
      "can√≥vanas_barrio-pueblo.txt\n",
      "caparra_archaeological_site.txt\n",
      "cape_san_juan_light.txt\n",
      "capilla_del_cristo.txt\n",
      "capitol_of_puerto_rico.txt\n",
      "caracas_beach_(vieques).txt\n",
      "cardona_(ponce).txt\n",
      "cardona_residence.txt\n",
      "caribe_hilton_hotel.txt\n",
      "carite_lake.txt\n",
      "carite_state_forest.txt\n",
      "carolina_barrio-pueblo.txt\n",
      "carra√≠zo_dam.txt\n",
      "casa_alonso.txt\n",
      "casa_blanca_(san_juan).txt\n",
      "casa_cauti√±o.txt\n",
      "casa_del_rey.txt\n",
      "casa_de_espa√±a.txt\n",
      "casa_dra._concha_melendez_ramirez.txt\n",
      "casa_fernando_luis_toro.txt\n",
      "casa_font-ubides.txt\n",
      "casa_franceschi_antongiorgi.txt\n",
      "casa_natal_de_luis_mu√±oz_rivera.txt\n",
      "casa_nemesio_canales.txt\n",
      "casa_oppenheimer.txt\n",
      "casa_paoli.txt\n",
      "casa_pueblo_puerto_rico.txt\n",
      "casa_roig_museum.txt\n",
      "casa_rosa.txt\n",
      "casa_rosita_serrall√©s.txt\n",
      "casa_salazar-candal.txt\n",
      "casa_serralles.txt\n",
      "casa_wiechers-villaronga.txt\n",
      "casona_c√©sari.txt\n",
      "castillo_san_crist√≥bal_(san_juan).txt\n",
      "castillo_san_felipe_del_morro.txt\n",
      "castillo_san_felipe_del_morro_lighthouse.txt\n",
      "castillo_serrall√©s.txt\n",
      "cata√±o_barrio-pueblo.txt\n",
      "catedral_de_nuestra_se√±ora_de_guadalupe.txt\n",
      "catedral_de_san_felipe_ap√≥stol_(arecibo,_puerto_rico).txt\n",
      "catedral_dulce_nombre_de_jes√∫s_(caguas,_puerto_rico).txt\n",
      "catedral_metropolitana_bas√≠lica_de_san_juan_bautista_(san_juan,_puerto_rico).txt\n",
      "cathedral_of_rum.txt\n",
      "cayey_barrio-pueblo.txt\n",
      "cayos_de_ca√±a_gorda.txt\n",
      "cayo_icacos.txt\n",
      "cayo_luis_pe√±a.txt\n",
      "ca√±o_tiburones.txt\n",
      "ceiba_barrio-pueblo.txt\n",
      "cementerio_cat√≥lico_san_vicente_de_paul.txt\n",
      "cementerio_civil_de_ponce.txt\n",
      "center_for_advanced_studies_on_puerto_rico_and_the_caribbean.txt\n",
      "central_aguirre_historic_district.txt\n",
      "central_cortada.txt\n",
      "central_gu√°nica.txt\n",
      "central_high_school_(san_juan,_puerto_rico).txt\n",
      "centro_ceremonial_ind√≠gena_de_tibes.txt\n",
      "centro_cultural_baudilio_vega_berr√≠os.txt\n",
      "centro_cultural_de_ponce_carmen_sol√°_de_pereira.txt\n",
      "centro_del_sur_mall.txt\n",
      "centro_de_convenciones_de_ponce.txt\n",
      "cerrillos_state_forest.txt\n",
      "cerro_de_punta.txt\n",
      "cerro_las_tetas.txt\n",
      "cerro_maravilla.txt\n",
      "cerro_morales_(utuado,_puerto_rico).txt\n",
      "cerro_rosa.txt\n",
      "cervecer√≠a_india.txt\n",
      "chalet_amill.txt\n",
      "christopher_columbus.txt\n",
      "church_of_saint_francis_of_assisi,_san_juan.txt\n",
      "church_of_san_francisco_de_as√≠s.txt\n",
      "church_of_san_mateo_de_cangrejos_of_santurce.txt\n",
      "church_san_blas_de_illescas_of_coamo.txt\n",
      "church_san_jos√©_of_aibonito.txt\n",
      "church_san_miguel_arc√°ngel_of_utuado.txt\n",
      "ciales_barrio-pueblo.txt\n",
      "cidra_barrio-pueblo.txt\n",
      "ciudad_deportiva_millito_navarro.txt\n",
      "club_deportivo_del_oeste.txt\n",
      "club_nautico_de_ponce.txt\n",
      "club_n√°utico_de_ponce.txt\n",
      "coamo_barrio-pueblo.txt\n",
      "coca-cola_music_hall.txt\n",
      "colegio_ponce√±o.txt\n",
      "colegio_san_conrado.txt\n",
      "coliseo_manuel_iguina.txt\n",
      "coliseo_rub√©n_rodr√≠guez.txt\n",
      "coloso_sugar_cane_refinery.txt\n",
      "comer√≠o_barrio-pueblo.txt\n",
      "complejo_recreativo_y_cultural_la_guancha.txt\n",
      "concatedral_dulce_nombre_de_jes√∫s_(humacao,_puerto_rico).txt\n",
      "condado_(santurce).txt\n",
      "condado_lagoon.txt\n",
      "condado_vanderbilt_hotel.txt\n",
      "conservatory_of_music_of_puerto_rico.txt\n",
      "corozal_barrio-pueblo.txt\n",
      "couroupita_nicaraguarensis.txt\n",
      "crash_boat_beach.txt\n",
      "cruceta_del_vig√≠a.txt\n",
      "cuevas_las_cabachuelas.txt\n",
      "cueva_del_indio_(arecibo).txt\n",
      "cueva_del_indio_(las_piedras).txt\n",
      "cueva_lucero.txt\n",
      "cueva_ventana.txt\n",
      "culebra_barrio-pueblo.txt\n",
      "culebra_national_wildlife_refuge.txt\n",
      "culebrita.txt\n",
      "dead_dog_beach.txt\n",
      "desecheo_national_wildlife_refuge.txt\n",
      "destiler√≠a_serrall√©s.txt\n",
      "district_courthouse_(aguadilla,_puerto_rico).txt\n",
      "domes_beach.txt\n",
      "dorado_barrio-pueblo.txt\n",
      "dos_bocas_lake.txt\n",
      "dos_hermanos_bridge.txt\n",
      "dr._juan_a._rivero_zoo.txt\n",
      "edificio_aboy.txt\n",
      "edificio_comunidad_de_orgullo_gay_de_puerto_rico.txt\n",
      "edificio_del_valle.txt\n",
      "edificio_jos√©_de_diego.txt\n",
      "edificio_oliver.txt\n",
      "edificio_patio_espa√±ol.txt\n",
      "edificio_victory_garden.txt\n",
      "el_falansterio_de_puerta_de_tierra.txt\n",
      "el_gigante_dormido.txt\n",
      "el_monumento_de_la_recordaci√≥n.txt\n",
      "el_parterre.txt\n",
      "el_toro_wilderness.txt\n",
      "el_tuque.txt\n",
      "el_yunque_national_forest.txt\n",
      "enrique_laguerre.txt\n",
      "ensenada_honda_(culebra,_puerto_rico).txt\n",
      "episcopal_cathedral_of_st._john_the_baptist_(san_juan,_puerto_rico).txt\n",
      "ermita_nuestra_se√±ora_de_la_valvanera.txt\n",
      "escuela_brambaugh.txt\n",
      "escuela_de_artes_pl√°sticas_y_dise√±o_de_puerto_rico.txt\n",
      "esperanza_beach.txt\n",
      "estadio_country_club.txt\n",
      "estadio_francisco_montaner.txt\n",
      "estadio_sixto_escobar.txt\n",
      "fajardo_barrio-pueblo.txt\n",
      "farmers'_market.txt\n",
      "faro_del_puerto_de_ponce.txt\n",
      "faro_de_la_isla_de_caja_de_muertos.txt\n",
      "filardi_house.txt\n",
      "flamenco_beach.txt\n",
      "florida,_puerto_rico.txt\n",
      "fort_buchanan,_puerto_rico.txt\n",
      "fort√≠n_de_san_ger√≥nimo.txt\n",
      "fort√≠n_san_antonio.txt\n",
      "fort√≠n_san_juan_de_la_cruz.txt\n",
      "francisco_oller.txt\n",
      "fuerte_de_la_concepci√≥n.txt\n",
      "fuerte_de_vieques.txt\n",
      "galer√≠a_nacional.txt\n",
      "gatas_(ponce).txt\n",
      "general_norzagaray_bridge.txt\n",
      "general_store.txt\n",
      "guajataca_lake.txt\n",
      "guajataca_state_forest.txt\n",
      "guajataca_tunnel.txt\n",
      "guavate,_cayey,_puerto_rico.txt\n",
      "guayama_barrio-pueblo.txt\n",
      "guayanilla_barrio-pueblo.txt\n",
      "guaynabo_barrio-pueblo.txt\n",
      "guilarte_state_forest.txt\n",
      "gurabo_barrio-pueblo.txt\n",
      "gu√°nica_barrio-pueblo.txt\n",
      "gu√°nica_light.txt\n",
      "gu√°nica_state_forest.txt\n",
      "g√≥mez_residence.txt\n",
      "hacienda_azucarera_la_esperanza.txt\n",
      "hacienda_buena_vista.txt\n",
      "hacienda_el_jibarito.txt\n",
      "hacienda_juanita.txt\n",
      "hacienda_lealtad.txt\n",
      "hacienda_santa_rita.txt\n",
      "hacienda_san_francisco.txt\n",
      "hatillo_barrio-pueblo.txt\n",
      "henry_klumb_house.txt\n",
      "hermitage_of_san_antonio_de_padua_de_la_tuna.txt\n",
      "hip√≥dromo_camarero.txt\n",
      "hiram_bithorn_stadium.txt\n",
      "hormigueros_barrio-pueblo.txt\n",
      "horse_racing.txt\n",
      "hotel_el_convento.txt\n",
      "hotel_melia.txt\n",
      "hotel_ponce_intercontinental.txt\n",
      "hotel_ponce_ramada.txt\n",
      "house_at_659_concordia_street.txt\n",
      "house_at_659_la_paz_street.txt\n",
      "house_at_663_la_paz_street.txt\n",
      "house_at_665_mckinley_street.txt\n",
      "humacao_barrio-pueblo.txt\n",
      "humacao_nature_reserve.txt\n",
      "h√∫cares.txt\n",
      "iglesia_de_la_sant√≠sima_trinidad.txt\n",
      "iglesia_de_nuestra_se√±ora_del_carmen.txt\n",
      "iglesia_de_san_antonio_de_padua.txt\n",
      "iglesia_san_germ√°n_de_auxerre.txt\n",
      "iglesia_san_sebasti√°n_m√°rtir.txt\n",
      "industrias_vassallo.txt\n",
      "institute_of_puerto_rican_culture.txt\n",
      "interamerican_university_of_puerto_rico.txt\n",
      "interamerican_university_of_puerto_rico_at_ponce.txt\n",
      "isabela_barrio-pueblo.txt\n",
      "isabel_ii_barrio-pueblo.txt\n",
      "isla_del_fr√≠o.txt\n",
      "isla_de_cabras.txt\n",
      "isla_de_jueyes.txt\n",
      "isla_de_mona.txt\n",
      "isla_de_ratones_(cabo_rojo,_puerto_rico).txt\n",
      "isla_de_ratones_(ponce,_puerto_rico).txt\n",
      "isla_magueyes.txt\n",
      "isla_mata_la_gata.txt\n",
      "isla_palomino.txt\n",
      "isla_verde,_puerto_rico.txt\n",
      "jayuya_barrio-pueblo.txt\n",
      "jes√∫s_izcoa_moure_bridge.txt\n",
      "jes√∫s_t._pi√±ero_house.txt\n",
      "jobos_beach.txt\n",
      "jose_v._toledo_federal_building_and_united_states_courthouse.txt\n",
      "jos√©_celso_barbosa.txt\n",
      "jos√©_miguel_agrelot_coliseum.txt\n",
      "joyuda,_puerto_rico.txt\n",
      "joyuda_lagoon.txt\n",
      "juana_d√≠az_barrio-pueblo.txt\n",
      "juan_boria.txt\n",
      "juan_ram√≥n_loubriel_stadium.txt\n",
      "julia_de_burgos.txt\n",
      "julio_enrique_monagas_park.txt\n",
      "juncos_barrio-pueblo.txt\n",
      "lago_dos_bocas.txt\n",
      "laguna_cartagena_national_wildlife_refuge.txt\n",
      "lajas_barrio-pueblo.txt\n",
      "lake_luchetti.txt\n",
      "lares_barrio-pueblo.txt\n",
      "lares_ice_cream_parlor.txt\n",
      "las_caba√±as_bridge.txt\n",
      "las_cascadas_water_park.txt\n",
      "las_catalinas_mall.txt\n",
      "las_mar√≠as_barrio-pueblo.txt\n",
      "las_piedras_barrio-pueblo.txt\n",
      "la_bombonera_(san_juan).txt\n",
      "la_concha_renaissance_san_juan_resort.txt\n",
      "la_cordillera_reef_nature_reserve.txt\n",
      "la_fortaleza.txt\n",
      "la_giralda_(san_juan,_puerto_rico).txt\n",
      "la_guancha_(ponce,_puerto_rico).txt\n",
      "la_liendre_bridge.txt\n",
      "la_mallorquina.txt\n",
      "la_parguera.txt\n",
      "la_perla,_san_juan,_puerto_rico.txt\n",
      "la_placita_de_santurce.txt\n",
      "la_plata_lake.txt\n",
      "la_pocita_de_las_golondrinas_beach.txt\n",
      "la_ventana_al_mar.txt\n",
      "lechon.txt\n",
      "legend_of_diego_salcedo.txt\n",
      "letras_de_ponce.txt\n",
      "lin-manuel_miranda.txt\n",
      "logia_mas√≥nica_hijos_de_la_luz.txt\n",
      "los_chinos_de_ponce.txt\n",
      "los_morrillos_lighthouse.txt\n",
      "los_tres_picachos.txt\n",
      "los_tres_picachos_state_forest.txt\n",
      "los_t√∫neles_subterr√°neos_de_san_germ√°n.txt\n",
      "loverbar.txt\n",
      "lo√≠za_barrio-pueblo.txt\n",
      "lo√≠za_lake.txt\n",
      "luis_a._ferr√©_performing_arts_center.txt\n",
      "luis_a._ferr√©_united_states_courthouse_and_post_office_building.txt\n",
      "luis_mu√±oz_mar√≠n_international_airport.txt\n",
      "luis_mu√±oz_mar√≠n_park.txt\n",
      "luis_mu√±oz_rivera_park.txt\n",
      "luquillo_barrio-pueblo.txt\n",
      "luquillo_beach.txt\n",
      "l√≠nea_avanzada.txt\n",
      "l√≥pez_residence.txt\n",
      "manat√≠_barrio-pueblo.txt\n",
      "manat√≠_bridge_at_mata_de_pl√°tano.txt\n",
      "maricao_barrio-pueblo.txt\n",
      "maricao_fish_hatchery.txt\n",
      "maricao_state_forest.txt\n",
      "mario_morales_coliseum.txt\n",
      "mart√≠n_pe√±a_bridge.txt\n",
      "mar_bella_beach.txt\n",
      "maunabo_barrio-pueblo.txt\n",
      "mavilla_bridge.txt\n",
      "mayag√ºez_barrio-pueblo.txt\n",
      "mayag√ºez_city_hall.txt\n",
      "mayag√ºez_resort_&_casino.txt\n",
      "mccabe_memorial_church.txt\n",
      "miramar_(santurce).txt\n",
      "mizpa_pentecostal_university.txt\n",
      "moca_barrio-pueblo.txt\n",
      "mona_ground_iguana.txt\n",
      "monte_jayuya.txt\n",
      "monumento_al_j√≠baro_puertorrique√±o.txt\n",
      "monumento_a_la_abolici√≥n_de_la_exclavitud.txt\n",
      "monumento_a_los_heroes_de_el_polvor√≠n_(obelisk).txt\n",
      "monumento_a_los_heroes_de_el_polvor√≠n_(tomb).txt\n",
      "morovis_barrio-pueblo.txt\n",
      "morovis_national_cemetery.txt\n",
      "morrillito.txt\n",
      "museo_castillo_serrall√©s.txt\n",
      "museo_del_autonomismo_puertorrique√±o.txt\n",
      "museo_de_arte_de_ponce.txt\n",
      "museo_de_la_arquitectura_ponce√±a.txt\n",
      "museo_de_la_historia_de_ponce.txt\n",
      "museo_de_la_masacre_de_ponce.txt\n",
      "museo_de_la_m√∫sica_puertorrique√±a.txt\n",
      "museo_de_vida_silvestre.txt\n",
      "museum_of_art_of_puerto_rico.txt\n",
      "museum_of_transportation_of_puerto_rico.txt\n",
      "naguabo_barrio-pueblo.txt\n",
      "naranjito_barrio-pueblo.txt\n",
      "normandie_hotel.txt\n",
      "nuestra_se√±ora_de_lourdes_chapel.txt\n",
      "nuevo_milenio_state_forest.txt\n",
      "ocean_park_(santurce).txt\n",
      "old_piedras_river_aqueduct.txt\n",
      "old_san_juan.txt\n",
      "orocovis.txt\n",
      "orocovis_barrio-pueblo.txt\n",
      "orthodox_judaism.txt\n",
      "our_lady_of_lourdes.txt\n",
      "pablo_casals_museum.txt\n",
      "palacete_los_moreau.txt\n",
      "palmas_del_mar.txt\n",
      "pante√≥n_nacional_rom√°n_baldorioty_de_castro.txt\n",
      "parque_del_litoral.txt\n",
      "parque_del_retiro.txt\n",
      "parque_del_tricentenario_(ponce,_puerto_rico).txt\n",
      "parque_de_bombas.txt\n",
      "parque_de_bombas_maximiliano_merced.txt\n",
      "parque_de_las_ciencias.txt\n",
      "parque_de_la_abolici√≥n.txt\n",
      "parque_de_la_ceiba.txt\n",
      "parque_ecol√≥gico_urbano.txt\n",
      "parque_familiar_julio_enrique_monagas.txt\n",
      "parque_lineal_veredas_del_labrador.txt\n",
      "parque_luis_a._wito_morales.txt\n",
      "parque_nacional_de_las_cavernas_del_r√≠o_camuy.txt\n",
      "parque_pedro_albizu_campos.txt\n",
      "parque_urbano_dora_col√≥n_clavell.txt\n",
      "parroquia_del_esp√≠ritu_santo_y_san_patricio.txt\n",
      "paseo_atocha.txt\n",
      "paseo_de_la_princesa.txt\n",
      "paseo_tablado_la_guancha.txt\n",
      "paseo_v√≠ctor_rojas.txt\n",
      "patillas_barrio-pueblo.txt\n",
      "pe√±uelas_barrio-pueblo.txt\n",
      "pico_piedra.txt\n",
      "pico_rodadero.txt\n",
      "pic√≥_pomar_residence.txt\n",
      "pi√±ones_state_forest.txt\n",
      "playa_espinar.txt\n",
      "playita_del_condado.txt\n",
      "plaza_carolina.txt\n",
      "plaza_col√≥n.txt\n",
      "plaza_col√≥n_(san_juan).txt\n",
      "plaza_degetau.txt\n",
      "plaza_del_caribe.txt\n",
      "plaza_del_mercado_de_ponce.txt\n",
      "plaza_del_norte.txt\n",
      "plaza_del_quinto_centenario.txt\n",
      "plaza_del_sol_(puerto_rico).txt\n",
      "plaza_de_armas,_san_juan.txt\n",
      "plaza_de_la_catedral_(san_juan).txt\n",
      "plaza_de_san_jos√©.txt\n",
      "plaza_juan_ponce_de_le√≥n.txt\n",
      "plaza_las_am√©ricas_(puerto_rico).txt\n",
      "plaza_las_delicias.txt\n",
      "plaza_mu√±oz_rivera.txt\n",
      "plaza_rio_hondo.txt\n",
      "polvor√≠n_de_miraflores.txt\n",
      "polytechnic_university_of_puerto_rico.txt\n",
      "ponce_cement,_inc..txt\n",
      "ponce_city_hall.txt\n",
      "ponce_high_school.txt\n",
      "ponce_historic_zone.txt\n",
      "ponce_school_of_medicine.txt\n",
      "ponce_ymca_building.txt\n",
      "pontificia_universidad_cat√≥lica_de_puerto_rico.txt\n",
      "porta_coeli_(puerto_rico).txt\n",
      "pozo_de_jacinto.txt\n",
      "primera_iglesia_bautista_de_caguas.txt\n",
      "primera_iglesia_metodista_unida_de_ponce.txt\n",
      "pueblo,_san_juan,_puerto_rico.txt\n",
      "puente_blanco.txt\n",
      "puente_de_coloso.txt\n",
      "puente_de_las_calabazas.txt\n",
      "puente_no._6.txt\n",
      "puerta_de_tierra,_san_juan.txt\n",
      "puerto_del_rey_marina.txt\n",
      "puerto_rico.txt\n",
      "puerto_rico_convention_center.txt\n",
      "puerto_rico_iron_works.txt\n",
      "puerto_rico_museum_of_contemporary_art.txt\n",
      "puerto_rico_national_library.txt\n",
      "punta_borinquen_light.txt\n",
      "punta_de_las_figuras_light.txt\n",
      "punta_higuero_light.txt\n",
      "punta_mulas_light.txt\n",
      "punta_santiago,_humacao,_puerto_rico.txt\n",
      "punta_tuna_light.txt\n",
      "quebradillas_barrio-pueblo.txt\n",
      "rafael_hern√°ndez_mar√≠n.txt\n",
      "ram√≥n_rivero_(diplo).txt\n",
      "residencia_aboy-lompr√©.txt\n",
      "residencia_armstrong-poventud.txt\n",
      "residencia_rosaly-batiz.txt\n",
      "residencia_subir√°.txt\n",
      "rinc√≥n_barrio-pueblo.txt\n",
      "roberto_clemente_coliseum.txt\n",
      "roberto_clemente_stadium.txt\n",
      "roosevelt_roads_naval_station.txt\n",
      "rovira_biscuits_corporation.txt\n",
      "rum.txt\n",
      "rum_planetarium.txt\n",
      "r√≠o_abajo_state_forest.txt\n",
      "r√≠o_grande_barrio-pueblo.txt\n",
      "r√≠o_grande_de_lo√≠za.txt\n",
      "r√≠o_mat√≥n_bridge.txt\n",
      "r√≠o_piedras_bridge.txt\n",
      "sabana_grande_barrio-pueblo.txt\n",
      "sabana_grande_masonic_cemetery.txt\n",
      "saint_john's_school_(san_juan).txt\n",
      "saliente_river.txt\n",
      "salinas_barrio-pueblo.txt\n",
      "samuel_morse.txt\n",
      "santa_ana_church_(san_juan).txt\n",
      "santa_isabel_barrio-pueblo.txt\n",
      "santa_mar√≠a_magdalena_de_pazzis_cemetery.txt\n",
      "santurce,_san_juan,_puerto_rico.txt\n",
      "san_crist√≥bal_canyon.txt\n",
      "san_germ√°n_historic_district.txt\n",
      "san_jos√©_church.txt\n",
      "san_juan_botanical_garden.txt\n",
      "san_juan_city_hall.txt\n",
      "san_juan_marriott_resort_&_stellaris_casino.txt\n",
      "san_juan_natatorium.txt\n",
      "san_juan_puerto_rico_temple.txt\n",
      "san_lorenzo_barrio-pueblo.txt\n",
      "san_miguel_arc√°ngel_church_(cabo_rojo).txt\n",
      "san_patricio_plaza.txt\n",
      "san_patricio_state_forest.txt\n",
      "san_sebasti√°n_barrio-pueblo.txt\n",
      "school_of_tropical_medicine_(puerto_rico).txt\n",
      "sixto_escobar.txt\n",
      "stud_farm.txt\n",
      "supreme_court_building_(puerto_rico).txt\n",
      "sus√∫a_state_forest.txt\n",
      "t-mobile_district.txt\n",
      "teatro_fox_delicias.txt\n",
      "teatro_la_perla.txt\n",
      "teatro_tapia.txt\n",
      "teatro_yag√ºez.txt\n",
      "teodoro_moscoso_bridge.txt\n",
      "the_mall_of_san_juan.txt\n",
      "tito_puente_amphitheatre.txt\n",
      "toa_alta_barrio-pueblo.txt\n",
      "toa_baja_barrio-pueblo.txt\n",
      "toro_negro_state_forest.txt\n",
      "tortuguero_lagoon.txt\n",
      "train_of_the_south.txt\n",
      "trujillo_alto_barrio-pueblo.txt\n",
      "u.s._custom_house_(san_juan,_puerto_rico).txt\n",
      "u.s._post_office_and_courthouse_(mayag√ºez,_puerto_rico).txt\n",
      "united_states_customs_house_(fajardo,_puerto_rico).txt\n",
      "united_states_customs_house_(ponce,_puerto_rico).txt\n",
      "united_states_district_court_for_the_district_of_puerto_rico.txt\n",
      "universidad_del_sagrado_coraz√≥n.txt\n",
      "university_gardens_high_school.txt\n",
      "university_high_school_(san_juan).txt\n",
      "university_of_puerto_rico,_medical_sciences_campus.txt\n",
      "university_of_puerto_rico,_r√≠o_piedras_campus.txt\n",
      "university_of_puerto_rico_at_cayey.txt\n",
      "university_of_puerto_rico_at_humacao.txt\n",
      "university_of_puerto_rico_at_mayag√ºez.txt\n",
      "university_of_puerto_rico_at_ponce.txt\n",
      "university_of_puerto_rico_school_of_medicine.txt\n",
      "uss_killen_(dd-593).txt\n",
      "utuado_barrio-pueblo.txt\n",
      "vega_alta_barrio-pueblo.txt\n",
      "vega_baja_barrio-pueblo.txt\n",
      "vega_state_forest.txt\n",
      "vieques_national_wildlife_refuge.txt\n",
      "villalba,_puerto_rico.txt\n",
      "villalba_barrio-pueblo.txt\n",
      "villa_pesquera.txt\n",
      "west_indian_manatee.txt\n",
      "whale_watching.txt\n",
      "william_miranda_mar√≠n_botanical_and_cultural_garden.txt\n",
      "world_war_ii.txt\n",
      "yabucoa_barrio-pueblo.txt\n",
      "yauco_barrio-pueblo.txt\n",
      "zona_historica_de_ponce.txt\n",
      "Adjuntas.txt\n",
      "Aguada.txt\n",
      "Aguadilla.txt\n",
      "Aguas Buenas.txt\n",
      "Aibonito.txt\n",
      "Arecibo.txt\n",
      "Arroyo.txt\n",
      "A√±asco.txt\n",
      "Barceloneta.txt\n",
      "Barranquitas.txt\n",
      "Bayam√≥n.txt\n",
      "Cabo Rojo.txt\n",
      "Caguas.txt\n",
      "Camuy.txt\n",
      "Can√≥vanas.txt\n",
      "Carolina.txt\n",
      "Cata√±o.txt\n",
      "Cayey.txt\n",
      "Ceiba.txt\n",
      "Ciales.txt\n",
      "Cidra.txt\n",
      "Coamo.txt\n",
      "Comer√≠o.txt\n",
      "Corozal.txt\n",
      "Culebra.txt\n",
      "Dorado.txt\n",
      "Fajardo.txt\n",
      "Florida.txt\n",
      "Guayama.txt\n",
      "Guayanilla.txt\n",
      "Guaynabo.txt\n",
      "Gurabo.txt\n",
      "Gu√°nica.txt\n",
      "Hatillo.txt\n",
      "Hormigueros.txt\n",
      "Humacao.txt\n",
      "Isabela.txt\n",
      "Jayuya.txt\n",
      "Juana D√≠az.txt\n",
      "Juncos.txt\n",
      "Lajas.txt\n",
      "Lares.txt\n",
      "Las Mar√≠as.txt\n",
      "Las Piedras.txt\n",
      "Lo√≠za.txt\n",
      "Luquillo.txt\n",
      "Manat√≠.txt\n",
      "Maricao.txt\n",
      "Maunabo.txt\n",
      "Mayag√ºez.txt\n",
      "Moca.txt\n",
      "Morovis.txt\n",
      "Naguabo.txt\n",
      "Naranjito.txt\n",
      "Orocovis.txt\n",
      "Patillas.txt\n",
      "Pe√±uelas.txt\n",
      "Ponce.txt\n",
      "Quebradillas.txt\n",
      "Rinc√≥n.txt\n",
      "R√≠o Grande.txt\n",
      "Sabana Grande.txt\n",
      "Salinas.txt\n",
      "San Germ√°n.txt\n",
      "San Juan.txt\n",
      "San Lorenzo.txt\n",
      "San Sebasti√°n.txt\n",
      "Santa Isabel.txt\n",
      "Toa Alta.txt\n",
      "Toa Baja.txt\n",
      "Trujillo Alto.txt\n",
      "Utuado.txt\n",
      "Vega Alta.txt\n",
      "Vega Baja.txt\n",
      "Vieques.txt\n",
      "Villalba.txt\n",
      "Yabucoa.txt\n",
      "Yauco.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to list .txt files in a directory\n",
    "def list_txt_files(directories):\n",
    "    txt_files = []\n",
    "    for directory in directories:\n",
    "        txt_files.extend([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')])\n",
    "    return txt_files\n",
    "\n",
    "# Main function to list .txt files in the specified directories\n",
    "def main(user_query):\n",
    "    data_directories = ['data/landmarks/landmarks', 'data/municipalities/municipalities']\n",
    "\n",
    "    txt_files = list_txt_files(data_directories)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the specified directories:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "    else:\n",
    "        print(\"No .txt files found in the specified directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    print(user_query)\n",
    "    main(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# esta respondiendo pero no me crea itinerario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan itinerary\n",
      "Welcome to the Travel Planner Chatbot!\n",
      "I can help you plan your itinerary. Let's get started!\n",
      "Great! Now, let's plan your itinerary from i want to go to Ponce\n",
      "Based on your preferences, here is your itinerary:\n",
      "Enjoy your trip!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to list .txt files in a directory\n",
    "def list_txt_files(directories):\n",
    "    txt_files = []\n",
    "    for directory in directories:\n",
    "        txt_files.extend([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')])\n",
    "    return txt_files\n",
    "\n",
    "# Function to handle the conversation with the chatbot\n",
    "def plan_itinerary_chatbot():\n",
    "    print(\"Welcome to the Travel Planner Chatbot!\")\n",
    "    print(\"I can help you plan your itinerary. Let's get started!\")\n",
    "\n",
    "    user_location = input(\"What is your starting location? \")\n",
    "    print(\"Great! Now, let's plan your itinerary from\", user_location)\n",
    "\n",
    "    # Add more questions here to gather information from the user\n",
    "\n",
    "    print(\"Based on your preferences, here is your itinerary:\")\n",
    "\n",
    "    # Add code to plan the itinerary based on user preferences\n",
    "\n",
    "    print(\"Enjoy your trip!\")\n",
    "\n",
    "# Main function to list .txt files in the specified directories\n",
    "def main():\n",
    "    data_directories = ['data/landmarks/landmarks', 'data/municipalities/municipalities',\n",
    "                        r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\"]\n",
    "\n",
    "    txt_files = list_txt_files(data_directories)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the specified directories:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "    else:\n",
    "        print(\"No .txt files found in the specified directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    print(user_query)\t\n",
    "    \n",
    "    if user_query.lower() == \"plan itinerary\":\n",
    "        plan_itinerary_chatbot()\n",
    "    else:\n",
    "        main()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan itinerary\n",
      "Welcome to the Travel Planner Chatbot!\n",
      "I can help you plan your itinerary. Let's get started!\n",
      "Great! Now, let's plan your itinerary from San Juan\n",
      "Based on your preferences, here is your itinerary:\n",
      "Enjoy your trip!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_directories = ['data/landmarks/landmarks', 'data/municipalities/municipalities',\n",
    "                        r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\"]\n",
    "\n",
    "    txt_files = list_txt_files(data_directories)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the specified directories:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "    else:\n",
    "        print(\"No .txt files found in the specified directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    print(user_query)\t\n",
    "\n",
    "    if user_query.lower() == \"plan itinerary\":\n",
    "        plan_itinerary_chatbot()\n",
    "    else:\n",
    "        main()\n",
    "\n",
    "def plan_itinerary_chatbot():\n",
    "    # Generate a travel itinerary for a trip to Puerto Rico\n",
    "    \n",
    "\n",
    "\n",
    "    # Example itinerary logic for a trip to Puerto Rico\n",
    "    itinerary = \"\"\"\n",
    "    Day 1: San Juan\n",
    "    - Explore Old San Juan and its colorful streets\n",
    "    - Visit El Morro and Castillo San Cristobal\n",
    "    - Enjoy traditional Puerto Rican cuisine for dinner\n",
    "\n",
    "    Day 2: El Yunque National Forest\n",
    "    - Hike the trails in the rainforest\n",
    "    - Visit La Mina Falls and Yokahu Tower\n",
    "    - Relax at Luquillo Beach\n",
    "\n",
    "    Day 3: Culebra Island\n",
    "    - Take a ferry to Culebra\n",
    "    - Snorkel at Flamenco Beach\n",
    "    - Visit Culebrita Island for amazing views\n",
    "\n",
    "    Day 4: Ponce\n",
    "    - Explore the historic district of Ponce\n",
    "    - Visit Museo de Arte de Ponce\n",
    "    - Enjoy local delicacies at a Ponce restaurant\n",
    "\n",
    "    Day 5: Rincon\n",
    "    - Experience the laid-back town of Rincon\n",
    "    - Relax at Sandy Beach\n",
    "    - Try surfing or paddleboarding\n",
    "\n",
    "    Day 6: Vieques Island\n",
    "    - Take a ferry to Vieques\n",
    "    - Explore Mosquito Bay for bioluminescent kayaking\n",
    "    - Enjoy a sunset beach BBQ\n",
    "\n",
    "    Day 7: Fajardo\n",
    "    - Visit Las Cabezas de San Juan Nature Reserve\n",
    "    - Enjoy a catamaran tour to snorkel at Icacos Island\n",
    "    - Farewell dinner at a seafood restaurant\n",
    "\n",
    "    Enjoy your trip to Puerto Rico!\n",
    "    \"\"\"\n",
    "\n",
    "    # Output the generated itinerary\n",
    "    print(\"Here is your personalized travel itinerary for Puerto Rico:\")\n",
    "    print(itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Puerto Rico Travel Itinerary:\n",
      "\n",
      "    Day 1: Arrival in San Juan\n",
      "    - Check into your hotel in Old San Juan\n",
      "    - Explore the historic streets and colorful buildings\n",
      "    - Visit El Morro Fortress for panoramic views\n",
      "    - Enjoy dinner at a local restaurant\n",
      "\n",
      "    Day 2: El Yunque National Forest\n",
      "    - Take a day trip to El Yunque Rainforest\n",
      "    - Hike to La Mina Falls and enjoy the lush beauty\n",
      "    - Have a picnic amidst nature\n",
      "    - Relax at Luquillo Beach in the afternoon\n",
      "\n",
      "    Day 3: Culebra Island Excursion\n",
      "    - Early morning ferry to Culebra Island\n",
      "    - Snorkel at Flamenco Beach, known for its crystal-clear waters\n",
      "    - Explore the unspoiled beauty of Culebra\n",
      "    - Enjoy a beachside lunch\n",
      "\n",
      "    Day 4: Rincon Surf Town\n",
      "    - Travel to Rincon on the west coast\n",
      "    - Try surfing or paddleboarding at Rincon Beach\n",
      "    - Relax on the sandy beaches and watch the sunset\n",
      "    - Explore the local surf culture\n",
      "\n",
      "    Day 5: Bioluminescent Bay in Vieques\n",
      "    - Take a boat tour to Mosquito Bay in Vieques\n",
      "    - Experience the magical bioluminescence at night\n",
      "    - Enjoy a seafood dinner by the bay\n",
      "\n",
      "    Day 6: Old Town Ponce\n",
      "    - Discover the colonial charm of Ponce\n",
      "    - Visit Plaza las Delicias and Ponce Cathedral\n",
      "    - Explore Museo de Arte de Ponce\n",
      "    - Sample authentic Puerto Rican cuisine\n",
      "\n",
      "    Day 7: Fajardo Adventures\n",
      "    - Head to Fajardo for outdoor adventures\n",
      "    - Kayak through the bioluminescent waters of Laguna Grande\n",
      "    - Snorkel at Seven Seas Beach\n",
      "    - Conclude your trip with a farewell dinner\n",
      "\n",
      "    Enjoy your unforgettable journey through the wonders of Puerto Rico!\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_puerto_rico_itinerary():\n",
    "    itinerary = \"\"\"\n",
    "    Puerto Rico Travel Itinerary:\n",
    "\n",
    "    Day 1: Arrival in San Juan\n",
    "    - Check into your hotel in Old San Juan\n",
    "    - Explore the historic streets and colorful buildings\n",
    "    - Visit El Morro Fortress for panoramic views\n",
    "    - Enjoy dinner at a local restaurant\n",
    "\n",
    "    Day 2: El Yunque National Forest\n",
    "    - Take a day trip to El Yunque Rainforest\n",
    "    - Hike to La Mina Falls and enjoy the lush beauty\n",
    "    - Have a picnic amidst nature\n",
    "    - Relax at Luquillo Beach in the afternoon\n",
    "\n",
    "    Day 3: Culebra Island Excursion\n",
    "    - Early morning ferry to Culebra Island\n",
    "    - Snorkel at Flamenco Beach, known for its crystal-clear waters\n",
    "    - Explore the unspoiled beauty of Culebra\n",
    "    - Enjoy a beachside lunch\n",
    "\n",
    "    Day 4: Rincon Surf Town\n",
    "    - Travel to Rincon on the west coast\n",
    "    - Try surfing or paddleboarding at Rincon Beach\n",
    "    - Relax on the sandy beaches and watch the sunset\n",
    "    - Explore the local surf culture\n",
    "\n",
    "    Day 5: Bioluminescent Bay in Vieques\n",
    "    - Take a boat tour to Mosquito Bay in Vieques\n",
    "    - Experience the magical bioluminescence at night\n",
    "    - Enjoy a seafood dinner by the bay\n",
    "\n",
    "    Day 6: Old Town Ponce\n",
    "    - Discover the colonial charm of Ponce\n",
    "    - Visit Plaza las Delicias and Ponce Cathedral\n",
    "    - Explore Museo de Arte de Ponce\n",
    "    - Sample authentic Puerto Rican cuisine\n",
    "\n",
    "    Day 7: Fajardo Adventures\n",
    "    - Head to Fajardo for outdoor adventures\n",
    "    - Kayak through the bioluminescent waters of Laguna Grande\n",
    "    - Snorkel at Seven Seas Beach\n",
    "    - Conclude your trip with a farewell dinner\n",
    "\n",
    "    Enjoy your unforgettable journey through the wonders of Puerto Rico!\n",
    "    \"\"\"\n",
    "\n",
    "    return itinerary\n",
    "\n",
    "# Generate the Puerto Rico travel itinerary\n",
    "puerto_rico_itinerary = generate_puerto_rico_itinerary()\n",
    "\n",
    "# Output the generated itinerary\n",
    "print(puerto_rico_itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your preferences for each day of the itinerary:\n",
      "\n",
      "    Puerto Rico Travel Itinerary Based on Your Preferences:\n",
      "\n",
      "    Day 1: Arrival in San Juan\n",
      "    - Check into your hotel in Old San Juan\n",
      "    - Explore the historic streets and colorful buildings\n",
      "    - Visit El Morro Fortress for panoramic views\n",
      "    - Enjoy dinner at a local restaurant\n",
      "\n",
      "    Day 2: go to the beach\n",
      "    - have a wonderful day\n",
      "\n",
      "    Day 3: go hiking\n",
      "    - see nature and enjoy the peace\n",
      "\n",
      "    Day 4: go to the clubs\n",
      "    - night life\n",
      "\n",
      "    Day 5: eat the best food\n",
      "    - cultural knowledge\n",
      "\n",
      "    Day 6: go to attractions\n",
      "    - enjoy the day\n",
      "\n",
      "    Day 7: more playas!\n",
      "    - Margaritas!\n",
      "\n",
      "    Enjoy your customized journey exploring the wonders of Puerto Rico!\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_puerto_rico_itinerary(user_preferences):\n",
    "    # Include user preferences to customize the itinerary\n",
    "    itinerary = f\"\"\"\n",
    "    Puerto Rico Travel Itinerary Based on Your Preferences:\n",
    "\n",
    "    Day 1: Arrival in San Juan\n",
    "    - Check into your hotel in Old San Juan\n",
    "    - Explore the historic streets and colorful buildings\n",
    "    - Visit El Morro Fortress for panoramic views\n",
    "    - Enjoy dinner at a local restaurant\n",
    "\n",
    "    Day 2: {user_preferences.get('day_2_activity')}\n",
    "    - {user_preferences.get('day_2_description')}\n",
    "\n",
    "    Day 3: {user_preferences.get('day_3_activity')}\n",
    "    - {user_preferences.get('day_3_description')}\n",
    "\n",
    "    Day 4: {user_preferences.get('day_4_activity')}\n",
    "    - {user_preferences.get('day_4_description')}\n",
    "\n",
    "    Day 5: {user_preferences.get('day_5_activity')}\n",
    "    - {user_preferences.get('day_5_description')}\n",
    "\n",
    "    Day 6: {user_preferences.get('day_6_activity')}\n",
    "    - {user_preferences.get('day_6_description')}\n",
    "\n",
    "    Day 7: {user_preferences.get('day_7_activity')}\n",
    "    - {user_preferences.get('day_7_description')}\n",
    "\n",
    "    Enjoy your customized journey exploring the wonders of Puerto Rico!\n",
    "    \"\"\"\n",
    "    return itinerary\n",
    "\n",
    "def get_user_preferences():\n",
    "    user_preferences = {}\n",
    "    print(\"Please provide your preferences for each day of the itinerary:\")\n",
    "    for day in range(2, 8):\n",
    "        user_preferences[f'day_{day}_activity'] = input(f\"Activity for Day {day}: \")\n",
    "        user_preferences[f'day_{day}_description'] = input(f\"Description for Day {day}: \")\n",
    "\n",
    "    return user_preferences\n",
    "\n",
    "# Get user preferences for each day\n",
    "user_preferences = get_user_preferences()\n",
    "\n",
    "# Generate the personalized Puerto Rico travel itinerary\n",
    "puerto_rico_itinerary = generate_puerto_rico_itinerary(user_preferences)\n",
    "\n",
    "# Output the customized itinerary\n",
    "print(puerto_rico_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " falta que el programa sea capaz de generar sus propias recomendaciones segun lo que quiera el usuario para hacer durante su visita. Codigo de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of .txt files in the specified directories:\n",
      "academia_del_perpetuo_socorro.txt\n",
      "academia_interamericana_metro.txt\n",
      "academia_maria_reina.txt\n",
      "academia_san_jorge.txt\n",
      "adjuntas_barrio-pueblo.txt\n",
      "aguada_barrio-pueblo.txt\n",
      "aguada_transmission_station.txt\n",
      "aguadilla_barrio-pueblo.txt\n",
      "aguadilla_ice_skating_arena.txt\n",
      "aguas_buenas_barrio-pueblo.txt\n",
      "aguas_buenas_cave_system.txt\n",
      "aguirre_state_forest.txt\n",
      "aibonito_barrio-pueblo.txt\n",
      "aibonito_festival_of_flowers.txt\n",
      "albergue_ol√≠mpico.txt\n",
      "albizu_university.txt\n",
      "ana_g._m√©ndez_university.txt\n",
      "antiguo_casino_de_ponce.txt\n",
      "antiguo_cuartel_militar_espa√±ol_de_ponce.txt\n",
      "antiguo_hospital_militar_espa√±ol_de_ponce.txt\n",
      "archivo_general_de_puerto_rico.txt\n",
      "arecibo_barrio-pueblo.txt\n",
      "arecibo_light.txt\n",
      "arecibo_observatory.txt\n",
      "arecibo_telescope.txt\n",
      "arenas_bridge.txt\n",
      "arroyo_barrio-pueblo.txt\n",
      "asilo_de_pobres.txt\n",
      "ateneo_puertorrique√±o.txt\n",
      "auditorio_juan_pach√≠n_vic√©ns.txt\n",
      "a√±asco_barrio-pueblo.txt\n",
      "bacardi.txt\n",
      "bah√≠a_de_jobos.txt\n",
      "ballaj√°_barracks.txt\n",
      "balneario_de_rinc√≥n.txt\n",
      "banco_cr√©dito_y_ahorro_ponce√±o_(building).txt\n",
      "banco_de_ponce_(building).txt\n",
      "barceloneta_barrio-pueblo.txt\n",
      "barranquitas_barrio-pueblo.txt\n",
      "bas√≠lica_menor_de_la_virgen_de_monserrate.txt\n",
      "bayam√≥n_barrio-pueblo.txt\n",
      "bayam√≥n_city_hall.txt\n",
      "bayam√≥n_river.txt\n",
      "ba√±os_de_coamo.txt\n",
      "biblical_magi.txt\n",
      "biblioteca_carnegie.txt\n",
      "biblioteca_municipal_de_ponce.txt\n",
      "birth_of_the_new_world.txt\n",
      "black_sand.txt\n",
      "blue_beach_(vieques).txt\n",
      "bobbin_lace.txt\n",
      "bolera_caribe.txt\n",
      "boquer√≥n,_cabo_rojo,_puerto_rico.txt\n",
      "boquer√≥n_state_forest.txt\n",
      "braulio_castillo.txt\n",
      "buy√©_beach.txt\n",
      "cabo_rojo_barrio-pueblo.txt\n",
      "cabo_rojo_national_wildlife_refuge.txt\n",
      "caf√©_rico.txt\n",
      "caguana_ceremonial_ball_courts_site.txt\n",
      "caguas_barrio-pueblo.txt\n",
      "caguas_city_hall.txt\n",
      "caguas_museum_of_art.txt\n",
      "caguas_museum_of_folk_arts.txt\n",
      "caguas_museum_of_tobacco.txt\n",
      "caguas_valley.txt\n",
      "caja_de_muertos.txt\n",
      "calle_25_de_enero.txt\n",
      "cambalache_forest_reserve.txt\n",
      "campamento_santiago.txt\n",
      "campo_atl√©tico_charles_h._terry.txt\n",
      "camuy_barrio-pueblo.txt\n",
      "camuy_river.txt\n",
      "can√≥vanas_barrio-pueblo.txt\n",
      "caparra_archaeological_site.txt\n",
      "cape_san_juan_light.txt\n",
      "capilla_del_cristo.txt\n",
      "capitol_of_puerto_rico.txt\n",
      "caracas_beach_(vieques).txt\n",
      "cardona_(ponce).txt\n",
      "cardona_residence.txt\n",
      "caribe_hilton_hotel.txt\n",
      "carite_lake.txt\n",
      "carite_state_forest.txt\n",
      "carolina_barrio-pueblo.txt\n",
      "carra√≠zo_dam.txt\n",
      "casa_alonso.txt\n",
      "casa_blanca_(san_juan).txt\n",
      "casa_cauti√±o.txt\n",
      "casa_del_rey.txt\n",
      "casa_de_espa√±a.txt\n",
      "casa_dra._concha_melendez_ramirez.txt\n",
      "casa_fernando_luis_toro.txt\n",
      "casa_font-ubides.txt\n",
      "casa_franceschi_antongiorgi.txt\n",
      "casa_natal_de_luis_mu√±oz_rivera.txt\n",
      "casa_nemesio_canales.txt\n",
      "casa_oppenheimer.txt\n",
      "casa_paoli.txt\n",
      "casa_pueblo_puerto_rico.txt\n",
      "casa_roig_museum.txt\n",
      "casa_rosa.txt\n",
      "casa_rosita_serrall√©s.txt\n",
      "casa_salazar-candal.txt\n",
      "casa_serralles.txt\n",
      "casa_wiechers-villaronga.txt\n",
      "casona_c√©sari.txt\n",
      "castillo_san_crist√≥bal_(san_juan).txt\n",
      "castillo_san_felipe_del_morro.txt\n",
      "castillo_san_felipe_del_morro_lighthouse.txt\n",
      "castillo_serrall√©s.txt\n",
      "cata√±o_barrio-pueblo.txt\n",
      "catedral_de_nuestra_se√±ora_de_guadalupe.txt\n",
      "catedral_de_san_felipe_ap√≥stol_(arecibo,_puerto_rico).txt\n",
      "catedral_dulce_nombre_de_jes√∫s_(caguas,_puerto_rico).txt\n",
      "catedral_metropolitana_bas√≠lica_de_san_juan_bautista_(san_juan,_puerto_rico).txt\n",
      "cathedral_of_rum.txt\n",
      "cayey_barrio-pueblo.txt\n",
      "cayos_de_ca√±a_gorda.txt\n",
      "cayo_icacos.txt\n",
      "cayo_luis_pe√±a.txt\n",
      "ca√±o_tiburones.txt\n",
      "ceiba_barrio-pueblo.txt\n",
      "cementerio_cat√≥lico_san_vicente_de_paul.txt\n",
      "cementerio_civil_de_ponce.txt\n",
      "center_for_advanced_studies_on_puerto_rico_and_the_caribbean.txt\n",
      "central_aguirre_historic_district.txt\n",
      "central_cortada.txt\n",
      "central_gu√°nica.txt\n",
      "central_high_school_(san_juan,_puerto_rico).txt\n",
      "centro_ceremonial_ind√≠gena_de_tibes.txt\n",
      "centro_cultural_baudilio_vega_berr√≠os.txt\n",
      "centro_cultural_de_ponce_carmen_sol√°_de_pereira.txt\n",
      "centro_del_sur_mall.txt\n",
      "centro_de_convenciones_de_ponce.txt\n",
      "cerrillos_state_forest.txt\n",
      "cerro_de_punta.txt\n",
      "cerro_las_tetas.txt\n",
      "cerro_maravilla.txt\n",
      "cerro_morales_(utuado,_puerto_rico).txt\n",
      "cerro_rosa.txt\n",
      "cervecer√≠a_india.txt\n",
      "chalet_amill.txt\n",
      "christopher_columbus.txt\n",
      "church_of_saint_francis_of_assisi,_san_juan.txt\n",
      "church_of_san_francisco_de_as√≠s.txt\n",
      "church_of_san_mateo_de_cangrejos_of_santurce.txt\n",
      "church_san_blas_de_illescas_of_coamo.txt\n",
      "church_san_jos√©_of_aibonito.txt\n",
      "church_san_miguel_arc√°ngel_of_utuado.txt\n",
      "ciales_barrio-pueblo.txt\n",
      "cidra_barrio-pueblo.txt\n",
      "ciudad_deportiva_millito_navarro.txt\n",
      "club_deportivo_del_oeste.txt\n",
      "club_nautico_de_ponce.txt\n",
      "club_n√°utico_de_ponce.txt\n",
      "coamo_barrio-pueblo.txt\n",
      "coca-cola_music_hall.txt\n",
      "colegio_ponce√±o.txt\n",
      "colegio_san_conrado.txt\n",
      "coliseo_manuel_iguina.txt\n",
      "coliseo_rub√©n_rodr√≠guez.txt\n",
      "coloso_sugar_cane_refinery.txt\n",
      "comer√≠o_barrio-pueblo.txt\n",
      "complejo_recreativo_y_cultural_la_guancha.txt\n",
      "concatedral_dulce_nombre_de_jes√∫s_(humacao,_puerto_rico).txt\n",
      "condado_(santurce).txt\n",
      "condado_lagoon.txt\n",
      "condado_vanderbilt_hotel.txt\n",
      "conservatory_of_music_of_puerto_rico.txt\n",
      "corozal_barrio-pueblo.txt\n",
      "couroupita_nicaraguarensis.txt\n",
      "crash_boat_beach.txt\n",
      "cruceta_del_vig√≠a.txt\n",
      "cuevas_las_cabachuelas.txt\n",
      "cueva_del_indio_(arecibo).txt\n",
      "cueva_del_indio_(las_piedras).txt\n",
      "cueva_lucero.txt\n",
      "cueva_ventana.txt\n",
      "culebra_barrio-pueblo.txt\n",
      "culebra_national_wildlife_refuge.txt\n",
      "culebrita.txt\n",
      "dead_dog_beach.txt\n",
      "desecheo_national_wildlife_refuge.txt\n",
      "destiler√≠a_serrall√©s.txt\n",
      "district_courthouse_(aguadilla,_puerto_rico).txt\n",
      "domes_beach.txt\n",
      "dorado_barrio-pueblo.txt\n",
      "dos_bocas_lake.txt\n",
      "dos_hermanos_bridge.txt\n",
      "dr._juan_a._rivero_zoo.txt\n",
      "edificio_aboy.txt\n",
      "edificio_comunidad_de_orgullo_gay_de_puerto_rico.txt\n",
      "edificio_del_valle.txt\n",
      "edificio_jos√©_de_diego.txt\n",
      "edificio_oliver.txt\n",
      "edificio_patio_espa√±ol.txt\n",
      "edificio_victory_garden.txt\n",
      "el_falansterio_de_puerta_de_tierra.txt\n",
      "el_gigante_dormido.txt\n",
      "el_monumento_de_la_recordaci√≥n.txt\n",
      "el_parterre.txt\n",
      "el_toro_wilderness.txt\n",
      "el_tuque.txt\n",
      "el_yunque_national_forest.txt\n",
      "enrique_laguerre.txt\n",
      "ensenada_honda_(culebra,_puerto_rico).txt\n",
      "episcopal_cathedral_of_st._john_the_baptist_(san_juan,_puerto_rico).txt\n",
      "ermita_nuestra_se√±ora_de_la_valvanera.txt\n",
      "escuela_brambaugh.txt\n",
      "escuela_de_artes_pl√°sticas_y_dise√±o_de_puerto_rico.txt\n",
      "esperanza_beach.txt\n",
      "estadio_country_club.txt\n",
      "estadio_francisco_montaner.txt\n",
      "estadio_sixto_escobar.txt\n",
      "fajardo_barrio-pueblo.txt\n",
      "farmers'_market.txt\n",
      "faro_del_puerto_de_ponce.txt\n",
      "faro_de_la_isla_de_caja_de_muertos.txt\n",
      "filardi_house.txt\n",
      "flamenco_beach.txt\n",
      "florida,_puerto_rico.txt\n",
      "fort_buchanan,_puerto_rico.txt\n",
      "fort√≠n_de_san_ger√≥nimo.txt\n",
      "fort√≠n_san_antonio.txt\n",
      "fort√≠n_san_juan_de_la_cruz.txt\n",
      "francisco_oller.txt\n",
      "fuerte_de_la_concepci√≥n.txt\n",
      "fuerte_de_vieques.txt\n",
      "galer√≠a_nacional.txt\n",
      "gatas_(ponce).txt\n",
      "general_norzagaray_bridge.txt\n",
      "general_store.txt\n",
      "guajataca_lake.txt\n",
      "guajataca_state_forest.txt\n",
      "guajataca_tunnel.txt\n",
      "guavate,_cayey,_puerto_rico.txt\n",
      "guayama_barrio-pueblo.txt\n",
      "guayanilla_barrio-pueblo.txt\n",
      "guaynabo_barrio-pueblo.txt\n",
      "guilarte_state_forest.txt\n",
      "gurabo_barrio-pueblo.txt\n",
      "gu√°nica_barrio-pueblo.txt\n",
      "gu√°nica_light.txt\n",
      "gu√°nica_state_forest.txt\n",
      "g√≥mez_residence.txt\n",
      "hacienda_azucarera_la_esperanza.txt\n",
      "hacienda_buena_vista.txt\n",
      "hacienda_el_jibarito.txt\n",
      "hacienda_juanita.txt\n",
      "hacienda_lealtad.txt\n",
      "hacienda_santa_rita.txt\n",
      "hacienda_san_francisco.txt\n",
      "hatillo_barrio-pueblo.txt\n",
      "henry_klumb_house.txt\n",
      "hermitage_of_san_antonio_de_padua_de_la_tuna.txt\n",
      "hip√≥dromo_camarero.txt\n",
      "hiram_bithorn_stadium.txt\n",
      "hormigueros_barrio-pueblo.txt\n",
      "horse_racing.txt\n",
      "hotel_el_convento.txt\n",
      "hotel_melia.txt\n",
      "hotel_ponce_intercontinental.txt\n",
      "hotel_ponce_ramada.txt\n",
      "house_at_659_concordia_street.txt\n",
      "house_at_659_la_paz_street.txt\n",
      "house_at_663_la_paz_street.txt\n",
      "house_at_665_mckinley_street.txt\n",
      "humacao_barrio-pueblo.txt\n",
      "humacao_nature_reserve.txt\n",
      "h√∫cares.txt\n",
      "iglesia_de_la_sant√≠sima_trinidad.txt\n",
      "iglesia_de_nuestra_se√±ora_del_carmen.txt\n",
      "iglesia_de_san_antonio_de_padua.txt\n",
      "iglesia_san_germ√°n_de_auxerre.txt\n",
      "iglesia_san_sebasti√°n_m√°rtir.txt\n",
      "industrias_vassallo.txt\n",
      "institute_of_puerto_rican_culture.txt\n",
      "interamerican_university_of_puerto_rico.txt\n",
      "interamerican_university_of_puerto_rico_at_ponce.txt\n",
      "isabela_barrio-pueblo.txt\n",
      "isabel_ii_barrio-pueblo.txt\n",
      "isla_del_fr√≠o.txt\n",
      "isla_de_cabras.txt\n",
      "isla_de_jueyes.txt\n",
      "isla_de_mona.txt\n",
      "isla_de_ratones_(cabo_rojo,_puerto_rico).txt\n",
      "isla_de_ratones_(ponce,_puerto_rico).txt\n",
      "isla_magueyes.txt\n",
      "isla_mata_la_gata.txt\n",
      "isla_palomino.txt\n",
      "isla_verde,_puerto_rico.txt\n",
      "jayuya_barrio-pueblo.txt\n",
      "jes√∫s_izcoa_moure_bridge.txt\n",
      "jes√∫s_t._pi√±ero_house.txt\n",
      "jobos_beach.txt\n",
      "jose_v._toledo_federal_building_and_united_states_courthouse.txt\n",
      "jos√©_celso_barbosa.txt\n",
      "jos√©_miguel_agrelot_coliseum.txt\n",
      "joyuda,_puerto_rico.txt\n",
      "joyuda_lagoon.txt\n",
      "juana_d√≠az_barrio-pueblo.txt\n",
      "juan_boria.txt\n",
      "juan_ram√≥n_loubriel_stadium.txt\n",
      "julia_de_burgos.txt\n",
      "julio_enrique_monagas_park.txt\n",
      "juncos_barrio-pueblo.txt\n",
      "lago_dos_bocas.txt\n",
      "laguna_cartagena_national_wildlife_refuge.txt\n",
      "lajas_barrio-pueblo.txt\n",
      "lake_luchetti.txt\n",
      "lares_barrio-pueblo.txt\n",
      "lares_ice_cream_parlor.txt\n",
      "las_caba√±as_bridge.txt\n",
      "las_cascadas_water_park.txt\n",
      "las_catalinas_mall.txt\n",
      "las_mar√≠as_barrio-pueblo.txt\n",
      "las_piedras_barrio-pueblo.txt\n",
      "la_bombonera_(san_juan).txt\n",
      "la_concha_renaissance_san_juan_resort.txt\n",
      "la_cordillera_reef_nature_reserve.txt\n",
      "la_fortaleza.txt\n",
      "la_giralda_(san_juan,_puerto_rico).txt\n",
      "la_guancha_(ponce,_puerto_rico).txt\n",
      "la_liendre_bridge.txt\n",
      "la_mallorquina.txt\n",
      "la_parguera.txt\n",
      "la_perla,_san_juan,_puerto_rico.txt\n",
      "la_placita_de_santurce.txt\n",
      "la_plata_lake.txt\n",
      "la_pocita_de_las_golondrinas_beach.txt\n",
      "la_ventana_al_mar.txt\n",
      "lechon.txt\n",
      "legend_of_diego_salcedo.txt\n",
      "letras_de_ponce.txt\n",
      "lin-manuel_miranda.txt\n",
      "logia_mas√≥nica_hijos_de_la_luz.txt\n",
      "los_chinos_de_ponce.txt\n",
      "los_morrillos_lighthouse.txt\n",
      "los_tres_picachos.txt\n",
      "los_tres_picachos_state_forest.txt\n",
      "los_t√∫neles_subterr√°neos_de_san_germ√°n.txt\n",
      "loverbar.txt\n",
      "lo√≠za_barrio-pueblo.txt\n",
      "lo√≠za_lake.txt\n",
      "luis_a._ferr√©_performing_arts_center.txt\n",
      "luis_a._ferr√©_united_states_courthouse_and_post_office_building.txt\n",
      "luis_mu√±oz_mar√≠n_international_airport.txt\n",
      "luis_mu√±oz_mar√≠n_park.txt\n",
      "luis_mu√±oz_rivera_park.txt\n",
      "luquillo_barrio-pueblo.txt\n",
      "luquillo_beach.txt\n",
      "l√≠nea_avanzada.txt\n",
      "l√≥pez_residence.txt\n",
      "manat√≠_barrio-pueblo.txt\n",
      "manat√≠_bridge_at_mata_de_pl√°tano.txt\n",
      "maricao_barrio-pueblo.txt\n",
      "maricao_fish_hatchery.txt\n",
      "maricao_state_forest.txt\n",
      "mario_morales_coliseum.txt\n",
      "mart√≠n_pe√±a_bridge.txt\n",
      "mar_bella_beach.txt\n",
      "maunabo_barrio-pueblo.txt\n",
      "mavilla_bridge.txt\n",
      "mayag√ºez_barrio-pueblo.txt\n",
      "mayag√ºez_city_hall.txt\n",
      "mayag√ºez_resort_&_casino.txt\n",
      "mccabe_memorial_church.txt\n",
      "miramar_(santurce).txt\n",
      "mizpa_pentecostal_university.txt\n",
      "moca_barrio-pueblo.txt\n",
      "mona_ground_iguana.txt\n",
      "monte_jayuya.txt\n",
      "monumento_al_j√≠baro_puertorrique√±o.txt\n",
      "monumento_a_la_abolici√≥n_de_la_exclavitud.txt\n",
      "monumento_a_los_heroes_de_el_polvor√≠n_(obelisk).txt\n",
      "monumento_a_los_heroes_de_el_polvor√≠n_(tomb).txt\n",
      "morovis_barrio-pueblo.txt\n",
      "morovis_national_cemetery.txt\n",
      "morrillito.txt\n",
      "museo_castillo_serrall√©s.txt\n",
      "museo_del_autonomismo_puertorrique√±o.txt\n",
      "museo_de_arte_de_ponce.txt\n",
      "museo_de_la_arquitectura_ponce√±a.txt\n",
      "museo_de_la_historia_de_ponce.txt\n",
      "museo_de_la_masacre_de_ponce.txt\n",
      "museo_de_la_m√∫sica_puertorrique√±a.txt\n",
      "museo_de_vida_silvestre.txt\n",
      "museum_of_art_of_puerto_rico.txt\n",
      "museum_of_transportation_of_puerto_rico.txt\n",
      "naguabo_barrio-pueblo.txt\n",
      "naranjito_barrio-pueblo.txt\n",
      "normandie_hotel.txt\n",
      "nuestra_se√±ora_de_lourdes_chapel.txt\n",
      "nuevo_milenio_state_forest.txt\n",
      "ocean_park_(santurce).txt\n",
      "old_piedras_river_aqueduct.txt\n",
      "old_san_juan.txt\n",
      "orocovis.txt\n",
      "orocovis_barrio-pueblo.txt\n",
      "orthodox_judaism.txt\n",
      "our_lady_of_lourdes.txt\n",
      "pablo_casals_museum.txt\n",
      "palacete_los_moreau.txt\n",
      "palmas_del_mar.txt\n",
      "pante√≥n_nacional_rom√°n_baldorioty_de_castro.txt\n",
      "parque_del_litoral.txt\n",
      "parque_del_retiro.txt\n",
      "parque_del_tricentenario_(ponce,_puerto_rico).txt\n",
      "parque_de_bombas.txt\n",
      "parque_de_bombas_maximiliano_merced.txt\n",
      "parque_de_las_ciencias.txt\n",
      "parque_de_la_abolici√≥n.txt\n",
      "parque_de_la_ceiba.txt\n",
      "parque_ecol√≥gico_urbano.txt\n",
      "parque_familiar_julio_enrique_monagas.txt\n",
      "parque_lineal_veredas_del_labrador.txt\n",
      "parque_luis_a._wito_morales.txt\n",
      "parque_nacional_de_las_cavernas_del_r√≠o_camuy.txt\n",
      "parque_pedro_albizu_campos.txt\n",
      "parque_urbano_dora_col√≥n_clavell.txt\n",
      "parroquia_del_esp√≠ritu_santo_y_san_patricio.txt\n",
      "paseo_atocha.txt\n",
      "paseo_de_la_princesa.txt\n",
      "paseo_tablado_la_guancha.txt\n",
      "paseo_v√≠ctor_rojas.txt\n",
      "patillas_barrio-pueblo.txt\n",
      "pe√±uelas_barrio-pueblo.txt\n",
      "pico_piedra.txt\n",
      "pico_rodadero.txt\n",
      "pic√≥_pomar_residence.txt\n",
      "pi√±ones_state_forest.txt\n",
      "playa_espinar.txt\n",
      "playita_del_condado.txt\n",
      "plaza_carolina.txt\n",
      "plaza_col√≥n.txt\n",
      "plaza_col√≥n_(san_juan).txt\n",
      "plaza_degetau.txt\n",
      "plaza_del_caribe.txt\n",
      "plaza_del_mercado_de_ponce.txt\n",
      "plaza_del_norte.txt\n",
      "plaza_del_quinto_centenario.txt\n",
      "plaza_del_sol_(puerto_rico).txt\n",
      "plaza_de_armas,_san_juan.txt\n",
      "plaza_de_la_catedral_(san_juan).txt\n",
      "plaza_de_san_jos√©.txt\n",
      "plaza_juan_ponce_de_le√≥n.txt\n",
      "plaza_las_am√©ricas_(puerto_rico).txt\n",
      "plaza_las_delicias.txt\n",
      "plaza_mu√±oz_rivera.txt\n",
      "plaza_rio_hondo.txt\n",
      "polvor√≠n_de_miraflores.txt\n",
      "polytechnic_university_of_puerto_rico.txt\n",
      "ponce_cement,_inc..txt\n",
      "ponce_city_hall.txt\n",
      "ponce_high_school.txt\n",
      "ponce_historic_zone.txt\n",
      "ponce_school_of_medicine.txt\n",
      "ponce_ymca_building.txt\n",
      "pontificia_universidad_cat√≥lica_de_puerto_rico.txt\n",
      "porta_coeli_(puerto_rico).txt\n",
      "pozo_de_jacinto.txt\n",
      "primera_iglesia_bautista_de_caguas.txt\n",
      "primera_iglesia_metodista_unida_de_ponce.txt\n",
      "pueblo,_san_juan,_puerto_rico.txt\n",
      "puente_blanco.txt\n",
      "puente_de_coloso.txt\n",
      "puente_de_las_calabazas.txt\n",
      "puente_no._6.txt\n",
      "puerta_de_tierra,_san_juan.txt\n",
      "puerto_del_rey_marina.txt\n",
      "puerto_rico.txt\n",
      "puerto_rico_convention_center.txt\n",
      "puerto_rico_iron_works.txt\n",
      "puerto_rico_museum_of_contemporary_art.txt\n",
      "puerto_rico_national_library.txt\n",
      "punta_borinquen_light.txt\n",
      "punta_de_las_figuras_light.txt\n",
      "punta_higuero_light.txt\n",
      "punta_mulas_light.txt\n",
      "punta_santiago,_humacao,_puerto_rico.txt\n",
      "punta_tuna_light.txt\n",
      "quebradillas_barrio-pueblo.txt\n",
      "rafael_hern√°ndez_mar√≠n.txt\n",
      "ram√≥n_rivero_(diplo).txt\n",
      "residencia_aboy-lompr√©.txt\n",
      "residencia_armstrong-poventud.txt\n",
      "residencia_rosaly-batiz.txt\n",
      "residencia_subir√°.txt\n",
      "rinc√≥n_barrio-pueblo.txt\n",
      "roberto_clemente_coliseum.txt\n",
      "roberto_clemente_stadium.txt\n",
      "roosevelt_roads_naval_station.txt\n",
      "rovira_biscuits_corporation.txt\n",
      "rum.txt\n",
      "rum_planetarium.txt\n",
      "r√≠o_abajo_state_forest.txt\n",
      "r√≠o_grande_barrio-pueblo.txt\n",
      "r√≠o_grande_de_lo√≠za.txt\n",
      "r√≠o_mat√≥n_bridge.txt\n",
      "r√≠o_piedras_bridge.txt\n",
      "sabana_grande_barrio-pueblo.txt\n",
      "sabana_grande_masonic_cemetery.txt\n",
      "saint_john's_school_(san_juan).txt\n",
      "saliente_river.txt\n",
      "salinas_barrio-pueblo.txt\n",
      "samuel_morse.txt\n",
      "santa_ana_church_(san_juan).txt\n",
      "santa_isabel_barrio-pueblo.txt\n",
      "santa_mar√≠a_magdalena_de_pazzis_cemetery.txt\n",
      "santurce,_san_juan,_puerto_rico.txt\n",
      "san_crist√≥bal_canyon.txt\n",
      "san_germ√°n_historic_district.txt\n",
      "san_jos√©_church.txt\n",
      "san_juan_botanical_garden.txt\n",
      "san_juan_city_hall.txt\n",
      "san_juan_marriott_resort_&_stellaris_casino.txt\n",
      "san_juan_natatorium.txt\n",
      "san_juan_puerto_rico_temple.txt\n",
      "san_lorenzo_barrio-pueblo.txt\n",
      "san_miguel_arc√°ngel_church_(cabo_rojo).txt\n",
      "san_patricio_plaza.txt\n",
      "san_patricio_state_forest.txt\n",
      "san_sebasti√°n_barrio-pueblo.txt\n",
      "school_of_tropical_medicine_(puerto_rico).txt\n",
      "sixto_escobar.txt\n",
      "stud_farm.txt\n",
      "supreme_court_building_(puerto_rico).txt\n",
      "sus√∫a_state_forest.txt\n",
      "t-mobile_district.txt\n",
      "teatro_fox_delicias.txt\n",
      "teatro_la_perla.txt\n",
      "teatro_tapia.txt\n",
      "teatro_yag√ºez.txt\n",
      "teodoro_moscoso_bridge.txt\n",
      "the_mall_of_san_juan.txt\n",
      "tito_puente_amphitheatre.txt\n",
      "toa_alta_barrio-pueblo.txt\n",
      "toa_baja_barrio-pueblo.txt\n",
      "toro_negro_state_forest.txt\n",
      "tortuguero_lagoon.txt\n",
      "train_of_the_south.txt\n",
      "trujillo_alto_barrio-pueblo.txt\n",
      "u.s._custom_house_(san_juan,_puerto_rico).txt\n",
      "u.s._post_office_and_courthouse_(mayag√ºez,_puerto_rico).txt\n",
      "united_states_customs_house_(fajardo,_puerto_rico).txt\n",
      "united_states_customs_house_(ponce,_puerto_rico).txt\n",
      "united_states_district_court_for_the_district_of_puerto_rico.txt\n",
      "universidad_del_sagrado_coraz√≥n.txt\n",
      "university_gardens_high_school.txt\n",
      "university_high_school_(san_juan).txt\n",
      "university_of_puerto_rico,_medical_sciences_campus.txt\n",
      "university_of_puerto_rico,_r√≠o_piedras_campus.txt\n",
      "university_of_puerto_rico_at_cayey.txt\n",
      "university_of_puerto_rico_at_humacao.txt\n",
      "university_of_puerto_rico_at_mayag√ºez.txt\n",
      "university_of_puerto_rico_at_ponce.txt\n",
      "university_of_puerto_rico_school_of_medicine.txt\n",
      "uss_killen_(dd-593).txt\n",
      "utuado_barrio-pueblo.txt\n",
      "vega_alta_barrio-pueblo.txt\n",
      "vega_baja_barrio-pueblo.txt\n",
      "vega_state_forest.txt\n",
      "vieques_national_wildlife_refuge.txt\n",
      "villalba,_puerto_rico.txt\n",
      "villalba_barrio-pueblo.txt\n",
      "villa_pesquera.txt\n",
      "west_indian_manatee.txt\n",
      "whale_watching.txt\n",
      "william_miranda_mar√≠n_botanical_and_cultural_garden.txt\n",
      "world_war_ii.txt\n",
      "yabucoa_barrio-pueblo.txt\n",
      "yauco_barrio-pueblo.txt\n",
      "zona_historica_de_ponce.txt\n",
      "Adjuntas.txt\n",
      "Aguada.txt\n",
      "Aguadilla.txt\n",
      "Aguas Buenas.txt\n",
      "Aibonito.txt\n",
      "Arecibo.txt\n",
      "Arroyo.txt\n",
      "A√±asco.txt\n",
      "Barceloneta.txt\n",
      "Barranquitas.txt\n",
      "Bayam√≥n.txt\n",
      "Cabo Rojo.txt\n",
      "Caguas.txt\n",
      "Camuy.txt\n",
      "Can√≥vanas.txt\n",
      "Carolina.txt\n",
      "Cata√±o.txt\n",
      "Cayey.txt\n",
      "Ceiba.txt\n",
      "Ciales.txt\n",
      "Cidra.txt\n",
      "Coamo.txt\n",
      "Comer√≠o.txt\n",
      "Corozal.txt\n",
      "Culebra.txt\n",
      "Dorado.txt\n",
      "Fajardo.txt\n",
      "Florida.txt\n",
      "Guayama.txt\n",
      "Guayanilla.txt\n",
      "Guaynabo.txt\n",
      "Gurabo.txt\n",
      "Gu√°nica.txt\n",
      "Hatillo.txt\n",
      "Hormigueros.txt\n",
      "Humacao.txt\n",
      "Isabela.txt\n",
      "Jayuya.txt\n",
      "Juana D√≠az.txt\n",
      "Juncos.txt\n",
      "Lajas.txt\n",
      "Lares.txt\n",
      "Las Mar√≠as.txt\n",
      "Las Piedras.txt\n",
      "Lo√≠za.txt\n",
      "Luquillo.txt\n",
      "Manat√≠.txt\n",
      "Maricao.txt\n",
      "Maunabo.txt\n",
      "Mayag√ºez.txt\n",
      "Moca.txt\n",
      "Morovis.txt\n",
      "Naguabo.txt\n",
      "Naranjito.txt\n",
      "Orocovis.txt\n",
      "Patillas.txt\n",
      "Pe√±uelas.txt\n",
      "Ponce.txt\n",
      "Quebradillas.txt\n",
      "Rinc√≥n.txt\n",
      "R√≠o Grande.txt\n",
      "Sabana Grande.txt\n",
      "Salinas.txt\n",
      "San Germ√°n.txt\n",
      "San Juan.txt\n",
      "San Lorenzo.txt\n",
      "San Sebasti√°n.txt\n",
      "Santa Isabel.txt\n",
      "Toa Alta.txt\n",
      "Toa Baja.txt\n",
      "Trujillo Alto.txt\n",
      "Utuado.txt\n",
      "Vega Alta.txt\n",
      "Vega Baja.txt\n",
      "Vieques.txt\n",
      "Villalba.txt\n",
      "Yabucoa.txt\n",
      "Yauco.txt\n",
      "\n",
      "Processing file: Puerto_Rico_Municipalities.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_txt_files(directories):\n",
    "    txt_files = []\n",
    "    for directory in directories:\n",
    "        # Check if it's actually a directory before listing its contents\n",
    "        if os.path.isdir(directory):\n",
    "            txt_files.extend([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')])\n",
    "    return txt_files\n",
    "\n",
    "def main():\n",
    "    # Only include actual directories here\n",
    "    data_directories = ['data/landmarks/landmarks', 'data/municipalities/municipalities']  # Only directories\n",
    "\n",
    "    txt_files = list_txt_files(data_directories)\n",
    "\n",
    "    if txt_files:\n",
    "        print(\"List of .txt files in the specified directories:\")\n",
    "        for txt_file in txt_files:\n",
    "            print(txt_file)\n",
    "\n",
    "    # Handle individual files separately if needed\n",
    "    file_to_process = 'Puerto_Rico_Municipalities.txt'\n",
    "    if os.path.isfile(file_to_process):\n",
    "        print(f\"\\nProcessing file: {file_to_process}\")\n",
    "        # Add logic to process this file as needed\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chatterbot\n",
      "  Downloading ChatterBot-1.2.0-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting mathparse<0.2,>=0.1 (from chatterbot)\n",
      "  Downloading mathparse-0.1.2-py3-none-any.whl.metadata (776 bytes)\n",
      "Requirement already satisfied: python-dateutil<2.10,>=2.9 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from chatterbot) (2.9.0.post0)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=2.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from chatterbot) (2.0.34)\n",
      "Requirement already satisfied: pytz in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from chatterbot) (2024.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from chatterbot) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<2.10,>=2.9->chatterbot) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from sqlalchemy<2.1,>=2.0->chatterbot) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from sqlalchemy<2.1,>=2.0->chatterbot) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->chatterbot) (0.4.6)\n",
      "Downloading ChatterBot-1.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Downloading mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n",
      "Installing collected packages: mathparse, chatterbot\n",
      "Successfully installed chatterbot-1.2.0 mathparse-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install chatterbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n"
     ]
    },
    {
     "ename": "ScannerError",
     "evalue": "while scanning for the next token\nfound character '\\t' that cannot start any token\n  in \"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt\", line 222, column 44",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the chatbot\u001b[39;00m\n\u001b[0;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ChatterBotCorpusTrainer(chatbot)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLatif-Calder√≥n\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mironhack 2024 2025\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchatterbot-corpus-master\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchatterbot_corpus\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLatif-Calder√≥n\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mironhack 2024 2025\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mproject-aieng-interactive-travel-planner\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPuerto_Rico_Municipalities.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/landmarks/landmarks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/municipalities/municipalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/elmundo_chunked_en_page1_15years/elmundo_chunked_en_page1_15years\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLatif-Calder√≥n\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mironhack 2024 2025\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mproject-aieng-interactive-travel-planner\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtraining_dataset.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Function to plan itinerary based on user preferences\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplan_itinerary\u001b[39m(user_input):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Add logic to plan itinerary based on user input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\chatterbot\\trainers.py:137\u001b[0m, in \u001b[0;36mChatterBotCorpusTrainer.train\u001b[1;34m(self, *corpus_paths)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m corpus_path \u001b[38;5;129;01min\u001b[39;00m corpus_paths:\n\u001b[0;32m    135\u001b[0m     data_file_paths\u001b[38;5;241m.\u001b[39mextend(list_corpus_files(corpus_path))\n\u001b[1;32m--> 137\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_file_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatements_to_create\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Train the chat bot with each statement and response pair\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\chatterbot\\corpus.py:84\u001b[0m, in \u001b[0;36mload_corpus\u001b[1;34m(*data_file_paths)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m data_file_paths:\n\u001b[0;32m     83\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 84\u001b[0m     corpus_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     conversations \u001b[38;5;241m=\u001b[39m corpus_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversations\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[0;32m     87\u001b[0m     corpus\u001b[38;5;241m.\u001b[39mextend(conversations)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\chatterbot\\corpus.py:59\u001b[0m, in \u001b[0;36mread_corpus\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionalDependencyImportError(message)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(file_name, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data_file:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_load\u001b[39m(stream):\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     80\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[1;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m     84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:110\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors[anchor] \u001b[38;5;241m=\u001b[39m node\n\u001b[0;32m    109\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSequenceEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, index))\n\u001b[0;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:379\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_first_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    377\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarks\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mstart_mark)\n\u001b[1;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_block_sequence_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:384\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(BlockEntryToken):\n\u001b[0;32m    383\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBlockEntryToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBlockEndToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_sequence_entry)\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_node()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mchoices):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\yaml\\scanner.py:258\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_plain()\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# No? It's an error. Let's produce a nice error message.\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile scanning for the next token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound character \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m that cannot start any token\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ch,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n",
      "\u001b[1;31mScannerError\u001b[0m: while scanning for the next token\nfound character '\\t' that cannot start any token\n  in \"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt\", line 222, column 44"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "from chatterbot.trainers import ListTrainer\n",
    "import yaml\n",
    "\n",
    "# Create a chatbot instance\n",
    "chatbot = ChatBot('PuertoRicoTravelAgent')\n",
    "\n",
    "# Train the chatbot\n",
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "\n",
    "trainer.train(r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\chatterbot-corpus-master\\chatterbot_corpus\\data\\english\", \n",
    "              r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt\",\n",
    "              \"data/landmarks/landmarks\", \"data/municipalities/municipalities\", \"data/elmundo_chunked_en_page1_15years/elmundo_chunked_en_page1_15years\",\n",
    "              r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\training_dataset.yml\")\n",
    "\n",
    "# Function to plan itinerary based on user preferences\n",
    "def plan_itinerary(user_input):\n",
    "    # Add logic to plan itinerary based on user input\n",
    "    keywords = ['destinations', 'activities', 'accommodations', 'dining', 'transportation', 'budget', 'duration', 'travel style', 'interests', 'preferences', 'itinerary',\n",
    "                'landmarks', 'municipalities', 'attractions', 'hotels', 'restaurants', 'cuisine', 'local experiences', 'day trips', 'sightseeing', 'shopping', 'adventure',\n",
    "                'culture', 'nature', 'relaxation', 'food', 'budget', 'luxury', 'moderate', 'seasonal highlights', 'weather', 'best time to visit', 'practical tips', 'safety',\n",
    "                'etiquette', 'money-saving tips', 'total trip cost', 'daily budget', 'day-by-day itinerary', 'day trips', 'local transportation', 'cultural experiences',\n",
    "                'local cuisine', 'recommended restaurants', 'guided tours', 'waterfalls', 'hiking trails', 'scenic views', 'historical sites', 'beaches', 'museums', 'parks']\n",
    "    matching_keywords = [keyword for keyword in keywords if keyword in user_input.lower()]\n",
    "\n",
    "    if matching_keywords:\n",
    "        return \"I recommend exploring the following options for your trip:\" [matching_keywords]\n",
    "    else:\n",
    "        return \"I recommend visiting Old San Juan, El Yunque National Forest, and enjoying traditional Puerto Rican cuisine while you're here.\"\n",
    "\n",
    "# Function to handle the conversation with the chatbot\n",
    "def chat_with_travel_agent():\n",
    "    conversation_history = []  # Store the conversation history\n",
    "    print(\"Welcome to the Puerto Rico Travel Planner Chatbot!\")\n",
    "    print(\"I can help you plan your itinerary for visiting Puerto Rico. Let's get started!\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Thank you for using the Puerto Rico Travel Planner Chatbot. Have a great trip!\")\n",
    "            break\n",
    "\n",
    "        # Add the user input to the conversation history\n",
    "        conversation_history.append(\"You: \" + user_input)\n",
    "\n",
    "        response = chatbot.get_response(user_input)\n",
    "\n",
    "        # Add the bot's response to the conversation history\n",
    "        conversation_history.append(\"PuertoRicoTravelAgent: \" + response.text)\n",
    "\n",
    "        print(\"PuertoRicoTravelAgent:\", response)\n",
    "\n",
    "        if \"plan itinerary\" in response.text.lower():\n",
    "            itinerary_recommendation = plan_itinerary(response.text)\n",
    "            print(\"PuertoRicoTravelAgent:\", itinerary_recommendation)\n",
    "            conversation_history.append(\"PuertoRicoTravelAgent: \" + itinerary_recommendation)\n",
    "\n",
    "        # Print out the conversation history\n",
    "        print(\"\\n\".join(conversation_history))\n",
    "\n",
    "'''def handle_conversation():\n",
    "    print(\"Welcome to the Puerto Rico Travel Planner Chatbot!\")\n",
    "    print(\"I can help you plan your itinerary for visiting Puerto Rico. Let's get started!\")\n",
    "\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    while user_input.lower() != 'exit':\n",
    "        print(\"You:\", user_input)\n",
    "        response = chatbot.get_response(user_input)\n",
    "        print(\"PuertoRicoTravelAgent:\", response)\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "    print(\"Thank you for using the Puerto Rico Travel Planner Chatbot. Have a great trip!\")'''\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    chat_with_travel_agent()\n",
    "    #handle_conversation() ###para que funcione el chatbot sin entrenar handle_conversation()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Welcome to the Puerto Rico Travel Planner Chatbot!\n",
      "I can help you plan your itinerary for visiting Puerto Rico. Let's get started!\n",
      "PuertoRicoTravelAgent: Actually I eat only electricity.\n",
      "PuertoRicoTravelAgent: Actually I eat only electricity.\n",
      "PuertoRicoTravelAgent: who is the governor\n",
      "Thank you for using the Puerto Rico Travel Planner Chatbot. Have a great trip!\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "\n",
    "# Create a chatbot instance\n",
    "chatbot = ChatBot('PuertoRicoTravelAgent')\n",
    "\n",
    "# Train the chatbot with relevant travel data\n",
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "trainer.train(r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\chatterbot-corpus-master\\chatterbot_corpus\\data\\english\", \n",
    "              \"data/landmarks/landmarks\", \"data/municipalities/municipalities\")\n",
    "\n",
    "# Function to plan itinerary based on user preferences\n",
    "def plan_itinerary(user_input):\n",
    "    # Add logic to plan itinerary based on user input\n",
    "    keywords = ['destinations', 'activities', 'accommodations', 'dining', 'transportation', 'budget', 'duration', 'travel style', 'interests', 'preferences', 'itinerary',\n",
    "                'landmarks', 'municipalities', 'attractions', 'hotels', 'restaurants', 'cuisine', 'local experiences', 'day trips', 'sightseeing', 'shopping', 'adventure',\n",
    "                'culture', 'nature', 'relaxation', 'food', 'budget', 'luxury', 'moderate', 'seasonal highlights', 'weather', 'best time to visit', 'practical tips', 'safety',\n",
    "                'etiquette', 'money-saving tips', 'total trip cost', 'daily budget', 'day-by-day itinerary', 'day trips', 'local transportation', 'cultural experiences',\n",
    "                'local cuisine', 'recommended restaurants', 'guided tours', 'waterfalls', 'hiking trails', 'scenic views', 'historical sites', 'beaches', 'museums', 'parks']\n",
    "    \n",
    "    #example of user input: \"I want to plan my itinerary for a 5-day trip to Puerto Rico with a moderate budget and a focus on culture and nature.\"\n",
    "    #analyze the user input to extract relevant keywords\n",
    "\n",
    "\n",
    "    matching_keywords = [keyword for keyword in keywords if keyword in user_input.lower()]\n",
    "\n",
    "    if matching_keywords:\n",
    "        return \"I recommend exploring the following options for your trip: [List of recommendations based on the keywords]\"\n",
    "    else:\n",
    "        return \"I recommend visiting Old San Juan, El Yunque National Forest, and enjoying traditional Puerto Rican cuisine while you're here.\"\n",
    "\n",
    "# Function to handle the conversation with the chatbot\n",
    "def chat_with_travel_agent():\n",
    "    conversation_history = []  # Store the conversation history\n",
    "    print(\"Welcome to the Puerto Rico Travel Planner Chatbot!\")\n",
    "    print(\"I can help you plan your itinerary for visiting Puerto Rico. Let's get started!\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Thank you for using the Puerto Rico Travel Planner Chatbot. Have a great trip!\")\n",
    "            break\n",
    "\n",
    "        # Add the user input to the conversation history\n",
    "        conversation_history.append(\"You: \" + user_input)\n",
    "\n",
    "        response = chatbot.get_response(user_input)\n",
    "\n",
    "        # Add the bot's response to the conversation history\n",
    "        conversation_history.append(\"PuertoRicoTravelAgent: \" + response.text)\n",
    "\n",
    "        print(\"PuertoRicoTravelAgent:\", response.text)\n",
    "\n",
    "        if \"plan itinerary\" in response.text.lower():\n",
    "            itinerary_recommendation = plan_itinerary(user_input)\n",
    "            print(\"PuertoRicoTravelAgent:\", itinerary_recommendation)\n",
    "            conversation_history.append(\"PuertoRicoTravelAgent: \" + itinerary_recommendation)\n",
    "\n",
    "        conversation_history.append(\"You: \" + user_input)\n",
    "        conversation_history.append(\"PuertoRicoTravelAgent: \" + response.text)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    chat_with_travel_agent()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai\n",
    " # create a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (4.48.2)\n",
      "Requirement already satisfied: openai in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (1.61.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\latif-calder√≥n\\anaconda33\\lib\\site-packages (from requests->transformers) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load 'psgs_w100.tsv.pkl'. Make sure that:\n\n- 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt' is a correct remote path to a directory containing a file named psgs_w100.tsv.pkl\n\n- or 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt' is the correct path to a directory containing a file named psgs_w100.tsv.pkl.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:117\u001b[0m, in \u001b[0;36mLegacyIndex._resolve_path\u001b[1;34m(self, index_path, filename)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:469\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    471\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m absolute_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLatif-Calder√≥n\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mironhack 2024 2025\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject-aieng-interactive-travel-planner\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPuerto_Rico_Municipalities.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the RAG Tokenizer, Retriever, and Token generator\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mRagRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/rag-token-nq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/dpr-question_encoder-single-nq-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlegacy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabsolute_path\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Or replace with a correctly-formulated relative path if applicable\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RagTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-nq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m generator \u001b[38;5;241m=\u001b[39m RagTokenForGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-nq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:451\u001b[0m, in \u001b[0;36mRagRetriever.from_pretrained\u001b[1;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m     index \u001b[38;5;241m=\u001b[39m CustomHFIndex(config\u001b[38;5;241m.\u001b[39mretrieval_vector_size, indexed_dataset)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    453\u001b[0m     config,\n\u001b[0;32m    454\u001b[0m     question_encoder_tokenizer\u001b[38;5;241m=\u001b[39mquestion_encoder_tokenizer,\n\u001b[0;32m    455\u001b[0m     generator_tokenizer\u001b[38;5;241m=\u001b[39mgenerator_tokenizer,\n\u001b[0;32m    456\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:419\u001b[0m, in \u001b[0;36mRagRetriever._build_index\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_build_index\u001b[39m(config):\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mindex_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 419\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLegacyIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieval_vector_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLEGACY_INDEX_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mindex_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m CustomHFIndex\u001b[38;5;241m.\u001b[39mload_from_disk(\n\u001b[0;32m    425\u001b[0m             vector_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mretrieval_vector_size,\n\u001b[0;32m    426\u001b[0m             dataset_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpassages_path,\n\u001b[0;32m    427\u001b[0m             index_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mindex_path,\n\u001b[0;32m    428\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:108\u001b[0m, in \u001b[0;36mLegacyIndex.__init__\u001b[1;34m(self, vector_size, index_path)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_id_to_db_id \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m index_path\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_passages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_size \u001b[38;5;241m=\u001b[39m vector_size\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:133\u001b[0m, in \u001b[0;36mLegacyIndex._load_passages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_passages\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    132\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading passages from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m     passages_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPASSAGE_FILENAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strtobool(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRUST_REMOTE_CODE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmalicious. It\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended to never unpickle data that could have come from an untrusted source, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat could have been tampered with. If you already verified the pickle data and decided to use it, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:124\u001b[0m, in \u001b[0;36mLegacyIndex._resolve_path\u001b[1;34m(self, index_path, filename)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Make sure that:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a correct remote path to a directory containing a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory containing a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(msg)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[0;32m    126\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_archive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load 'psgs_w100.tsv.pkl'. Make sure that:\n\n- 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt' is a correct remote path to a directory containing a file named psgs_w100.tsv.pkl\n\n- or 'C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\Puerto_Rico_Municipalities.txt' is the correct path to a directory containing a file named psgs_w100.tsv.pkl.\n\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "import openai\n",
    "import os\n",
    "os.environ[\"TRUST_REMOTE_CODE\"] = \"True\"\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key =' 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'\n",
    "\n",
    "absolute_path = r\"C:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\\psgs_w100.tsv.pkl\"\n",
    "\n",
    "# Load the RAG Tokenizer, Retriever, and Token generator\n",
    "retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-token-nq\",\n",
    "    retriever_name=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    index_name=\"legacy\",\n",
    "    index_path=absolute_path  # Or replace with a correctly-formulated relative path if applicable\n",
    ")\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "generator = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\")\n",
    "\n",
    "\n",
    "# Function to get relevant information about Puerto Rico using RAG\n",
    "def get_puerto_rico_info(query):\n",
    "    # Obtain relevant information about Puerto Rico from the RAG system\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        ret_output = retriever(**inputs)\n",
    "        label_ids = ret_output[\"retrieved_doc_embeds\"]\n",
    "        outputs = generator(input_ids=inputs[\"input_ids\"], retrieved_doc_embeds=label_ids)\n",
    "        response = tokenizer.batch_decode(outputs[\"output_ids\"], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Main function for interacting with the chatbot\n",
    "def chat_with_travelers_guide():\n",
    "    print(\"Welcome to the Traveler's Guide Chatbot for Puerto Rico!\")\n",
    "    user_query = input(\"You: \")\n",
    "\n",
    "    response = get_puerto_rico_info(user_query)\n",
    "    print(\"Traveler's Guide Chatbot:\", response)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    chat_with_travelers_guide()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Latif-Calder√≥n\\OneDrive\\Documents\\ironhack 2024 2025\\project-aieng-interactive-travel-planner\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Current directory where the notebook is executing\n",
    "print(os.path.exists(absolute_path))  # Check if the path correctly resolves to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Traveler's Guide to Puerto Rico!\n",
      "Choose a destination to learn more:\n",
      "elmundo_chunked_en_page1_15y\n",
      "elmundo_chunked_en_page1_15years\n",
      "elmundo_chunked_es_page1_15y\n",
      "elmundo_chunked_es_page1_15years\n",
      "elmundo_chunked_es_page1_40y\n",
      "elmundo_chunked_es_page1_40years\n",
      "landm\n",
      "landmarks\n",
      "links to larger datasets\n",
      "municipali\n",
      "municipalities\n",
      "Destination not found. Please try again.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "# Load the English language model in spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# Function to extract destination information from text files using spaCy\n",
    "def extract_info_from_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        doc = nlp(text)\n",
    "\n",
    "        description = ''\n",
    "        things_to_do = []\n",
    "\n",
    "        # Extract sentences that contain descriptions and things to do\n",
    "        for sentence in doc.sents:\n",
    "            if 'description' in sentence.text.lower():\n",
    "                description = sentence.text.replace('Description:', '').strip()\n",
    "            elif 'things to do' in sentence.text.lower():\n",
    "                activities = sentence.text.replace('Things to do:', '').split('\\n')\n",
    "                things_to_do = [activity.strip() for activity in activities if activity.strip()]\n",
    "\n",
    "        return description, things_to_do\n",
    "\n",
    "# Function to display destination information\n",
    "def display_destination(destination):\n",
    "    file_path = os.path.join('data', destination + '.txt')\n",
    "    description, things_to_do = extract_info_from_text_file(file_path)\n",
    "    print(\"Destination: \" + destination)\n",
    "    print(\"Description: \" + description)\n",
    "    print(\"Things to do:\")\n",
    "    for activity in things_to_do:\n",
    "        print(\"- \" + activity)\n",
    "\n",
    "# Main function to ask user for input and display destination information\n",
    "def main():\n",
    "    print(\"Welcome to the Traveler's Guide to Puerto Rico!\")\n",
    "    print(\"Choose a destination to learn more:\")\n",
    "\n",
    "    # Get a list of destination folders in the 'data' directory\n",
    "    destination_folders = os.listdir('data')\n",
    "    destinations = [folder[:-4] for folder in destination_folders]  # Remove the '.txt' extension\n",
    "    for destination in destinations:\n",
    "        print(destination)\n",
    "\n",
    "    choice = input(\"Enter the destination you want to learn more about: \")\n",
    "    if choice in destinations:\n",
    "        display_destination(choice)\n",
    "    else:\n",
    "        print(\"Destination not found. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG transfrmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calder√≥n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\latif-calder√≥n\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ca1fbac1c4034a869cfdce521ae69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4342262fb64e5e94c23fecabd5c4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)ncoder_tokenizer%2Ftokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2579cdab6b64b84a7fc1740d41b2e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "question_encoder_tokenizer%2Fvocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7c432af3e84c3ca390c0eceb4de01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)oder_tokenizer%2Fspecial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360c26524f8642168147f77649ee347b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)erator_tokenizer%2Ftokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac708d09289f42e9b4ae113abdaff263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generator_tokenizer%2Fvocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaefd14faf64aa88df1d3c94a623d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generator_tokenizer%2Fmerges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ecf753dac74edcb4d50cb6d40a2847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)ator_tokenizer%2Fspecial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08ba150f46e431faac60df315b906d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0857347429b04c99a289b339be83a900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wiki_dpr.py:   0%|          | 0.00/8.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the RAG model and tokenizer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mRagRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/rag-token-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RagTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m generator \u001b[38;5;241m=\u001b[39m RagSequenceForGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:451\u001b[0m, in \u001b[0;36mRagRetriever.from_pretrained\u001b[1;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m     index \u001b[38;5;241m=\u001b[39m CustomHFIndex(config\u001b[38;5;241m.\u001b[39mretrieval_vector_size, indexed_dataset)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    453\u001b[0m     config,\n\u001b[0;32m    454\u001b[0m     question_encoder_tokenizer\u001b[38;5;241m=\u001b[39mquestion_encoder_tokenizer,\n\u001b[0;32m    455\u001b[0m     generator_tokenizer\u001b[38;5;241m=\u001b[39mgenerator_tokenizer,\n\u001b[0;32m    456\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:430\u001b[0m, in \u001b[0;36mRagRetriever._build_index\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CustomHFIndex\u001b[38;5;241m.\u001b[39mload_from_disk(\n\u001b[0;32m    425\u001b[0m         vector_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mretrieval_vector_size,\n\u001b[0;32m    426\u001b[0m         dataset_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpassages_path,\n\u001b[0;32m    427\u001b[0m         index_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mindex_path,\n\u001b[0;32m    428\u001b[0m     )\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCanonicalHFIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieval_vector_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_dummy_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_dummy_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:280\u001b[0m, in \u001b[0;36mCanonicalHFIndex.__init__\u001b[1;34m(self, vector_size, dataset_name, dataset_split, index_name, index_path, use_dummy_dataset, dataset_revision)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_revision \u001b[38;5;241m=\u001b[39m dataset_revision\n\u001b[0;32m    279\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading passages from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_dummy_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(vector_size, dataset, index_initialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2124\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2125\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2126\u001b[0m )\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2129\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1849\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1847\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1848\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1849\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1731\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1726\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1727\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1728\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1729\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1730\u001b[0m                     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1731\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trust_remote_code:\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1734\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1735\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1681\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1672\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;66;03m# Otherwise we must use the dataset script if the user trusts it\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[0;32m   1683\u001b[0m     \u001b[38;5;66;03m# Use the infos from the parquet export except in some cases:\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mor\u001b[39;00m data_files \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1331\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m importable_file_path \u001b[38;5;241m=\u001b[39m _get_importable_file_path(\n\u001b[0;32m   1325\u001b[0m     dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[0;32m   1326\u001b[0m     module_namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1327\u001b[0m     subdirectory_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhash\u001b[39m,\n\u001b[0;32m   1328\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   1329\u001b[0m )\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(importable_file_path):\n\u001b[1;32m-> 1331\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_trust_remote_code\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n\u001b[0;32m   1333\u001b[0m         _create_importable_file(\n\u001b[0;32m   1334\u001b[0m             local_path\u001b[38;5;241m=\u001b[39mlocal_path,\n\u001b[0;32m   1335\u001b[0m             local_imports\u001b[38;5;241m=\u001b[39mlocal_imports,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1341\u001b[0m             download_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_mode,\n\u001b[0;32m   1342\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:138\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[1;34m(trust_remote_code, repo_id)\u001b[0m\n\u001b[0;32m    135\u001b[0m         signal\u001b[38;5;241m.\u001b[39malarm(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;66;03m# OS which does not support signal.SIGALRM\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe repository for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m contains custom code which must be executed to correctly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload the dataset. You can inspect the repository content at https://hf.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# For the CI which might put the timeout at 0\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run."
     ]
    }
   ],
   "source": [
    "from transformers import RagRetriever, RagTokenizer, RagTokenizer, RagSequenceForGeneration\n",
    "import os\n",
    "\n",
    "# Load the RAG model and tokenizer\n",
    "ret = RagRetriever.from_pretrained(\"facebook/rag-token-base\")\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "generator = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")\n",
    "\n",
    "# Folder paths\n",
    "folders = [\"elmundo_chunked_en_page1_15years\", \"elmundo_chunked_es_page1_15years\", \n",
    "           \"elmundo_chunked_es_page1_40years\", \"landmarks\", \"municipalities\"]\n",
    "data_directory = 'data'\n",
    "\n",
    "# Dictionary to store extracted information\n",
    "data = {}\n",
    "\n",
    "# Retrieve information from text files in specified folders\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_directory, folder)\n",
    "    data[folder] = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                text = file.read()\n",
    "                data[folder].append(text)\n",
    "\n",
    "# Index the extracted information\n",
    "indexed_data = {key: tokenizer(value, return_tensors=\"pt\") for key, value in data.items()}\n",
    "\n",
    "# Function to query the RAG model for answers\n",
    "def query_rag_model(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = generator(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask']).choices\n",
    "    return outputs\n",
    "\n",
    "# Ask a question and retrieve an answer using the RAG model\n",
    "question = \"What are the landmarks in Puerto Rico?\"\n",
    "answer = query_rag_model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a68480521c4de892b8669419ab154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380ba1561f9f44388fa3a8ed73002f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "generator = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")\n",
    "# Function to query the RAG model for answers\n",
    "def query_rag_model(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = generator(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask']).choices\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RetrievAugLMMarginOutput' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Ask a question and retrieve an answer using the RAG model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the landmarks in Puerto Rico?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mquery_rag_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m, in \u001b[0;36mquery_rag_model\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(question, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RetrievAugLMMarginOutput' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "# Set the retriever for the RAG model to provide context for the question\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "generator.set_retriever(retriever)\n",
    "\n",
    "# Ask a question and retrieve an answer using the RAG model\n",
    "question = \"What are the landmarks in Puerto Rico?\"\n",
    "answer = query_rag_model(question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed0a096b6bb4107953411874601ce6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/157 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf7553b69a9420196932792e27e36b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f8d04593304432a2741e52f47b16ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00157.parquet:   0%|          | 0.00/546M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fdb6ac8508489ebf7a99efea748868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00157.parquet:   0%|          | 0.00/546M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b61781c03a4b2cb002afb1cc19df4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00157.parquet:   0%|          | 0.00/546M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564a8b2f2d9748618dbd569946979a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00157.parquet:   0%|          | 0.00/546M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d9499b013f4a56bdeb16dead4edf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19256cbb3df4b76be075f9ad17344a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ccd802ea6343b484dbd0e18cc70f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00157.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaf85ffbea440e6a8184ea65486827a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00157.parquet:   0%|          | 0.00/530M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de90e834d3324ada88e14f139da39d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00157.parquet:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519e282107ce4f9a8f83464881f9414c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00157.parquet:   0%|          | 0.00/546M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76285ad6dffd4e8ba7a59446fe3349ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0439bdafd4ea1afa55302632ed3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a4c7c0066450c8c529c3f6d441f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a855de3e15c84b69855611fe8834fabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c22bf319014b6991b20343a9d351f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfabe8f7d2e543cbbdc3af35e9508ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3177529e65f84c34b28c27eb31b0b32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00017-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9ddb9ed7f74a749afb80120df38b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00018-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd834c7997ae45a288c83195a9d27109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00019-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b995e2fcb8450895219caa0f1a46dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00020-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91412a7b2307478e8a16a6cf6fb7af4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00021-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa52249db8247349957ff2d85a875d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00022-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2efb06fbd94d3dac87957c88455b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00023-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1677265c52b84e66bcf88e34bb3a8147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00024-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c87b13129a6477c8109acd9d09da1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00025-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb039c15c0040debaaa8b8b6afa6297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00026-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6b47d14d7246d7ab5cfc1d1fe77eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00027-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3251b9e77d5496fbdf659796955fca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00028-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb279537c1eb4c50a683f79ead740936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00029-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae57b2e13c944bfc822bebb0a0df6e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00030-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810bf0a2fb1a4fee8c0d6c3fa6b57f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00031-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b0c8e44da42d9ac7f70afb0fea27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00032-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec4780570094e19b9686cf7eae3506e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00033-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d70a86a47314b6ea383cc2bf97960c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00034-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d72e547bf534b6f8643bf3e14181506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00035-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8be05553c8b4c69b72221abaa2a13c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00036-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2d7b4c41b5493c874156734421ade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00037-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc69bc868fd84c64bb687607d21d59ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00038-of-00157.parquet:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb0562a5a3f41e6ac1e562083258b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00039-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be3029167d54c3caa63ebab337cc500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00040-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955e2e0cecdf460c8db6c674d5af5118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00041-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e286699ffdbf4d8f914067ec7e3d9748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00042-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f95377082334b4a97fcd43818c50818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00043-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454bce23243548a2b5b00bbe956a1ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00044-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f196a92866445ee844075829099f928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00045-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aed92125c64f81af80b1dd895c6acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00046-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095dc82416b441509b1abdecfef7041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00047-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd393fef35e487ba62b40cd59d63bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00048-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f663ec5afb034fd98a7a12e4bac1b2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00049-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0fe21ca38842a6aedc5cbdba930e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00050-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2a649187f9415b904901509f1f74c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00051-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de3c69b47ab4410815c85f7af22b56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00053-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:369\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:93\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[1;31mReadTimeout\u001b[0m: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 64d73e1b-84ec-496f-a357-97c849e7ac12)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:188\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    197\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[0;32m    198\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[0;32m    199\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[0;32m    200\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[0;32m    201\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\hf_api.py:5252\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[1;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   5250\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m-> 5252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5255\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5268\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:967\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1485\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m-> 1485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1488\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1489\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhead_call_error\u001b[39;00m\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset with trust_remote_code=True\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwiki_dpr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpsgs_w100.nq.exact\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2151\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[0;32m   2150\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 2151\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   2160\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2161\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   2162\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:924\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    923\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 924\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:978\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[0;32m    977\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[1;32m--> 978\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\wiki_dpr\\66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c\\wiki_dpr.py:143\u001b[0m, in \u001b[0;36mWikiDpr._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    141\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mwiki_split, data_dir)\n\u001b[0;32m    142\u001b[0m files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-of-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_shards\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_shards)]\n\u001b[1;32m--> 143\u001b[0m downloaded_files \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    145\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mSplitGenerator(name\u001b[38;5;241m=\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mTRAIN, gen_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m: downloaded_files}),\n\u001b[0;32m    146\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[0;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    157\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[1;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:512\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m    511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 512\u001b[0m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[0;32m    514\u001b[0m ]\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[0;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:380\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    375\u001b[0m     batched\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[0;32m    379\u001b[0m ):\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:206\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[1;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     max_workers \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    203\u001b[0m         config\u001b[38;5;241m.\u001b[39mHF_DATASETS_MULTITHREADING_MAX_WORKERS \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    204\u001b[0m     )  \u001b[38;5;66;03m# enable multithreading if files are small\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# contains the ranks of subprocesses\u001b[39;49;00m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHF_DATASETS_STACK_MULTIPROCESSING_DOWNLOAD_PROGRESS_BARS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identity\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[0;32m    222\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[1;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[1;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[0;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[1;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[1;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[0;32m    231\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:202\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         output_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfApi(\n\u001b[0;32m    183\u001b[0m             endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT,\n\u001b[0;32m    184\u001b[0m             token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m    195\u001b[0m         )\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    197\u001b[0m         huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[0;32m    198\u001b[0m         huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[0;32m    199\u001b[0m         huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[0;32m    200\u001b[0m         huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[0;32m    201\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Download external files\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m get_from_cache(\n\u001b[0;32m    206\u001b[0m         url_or_filename,\n\u001b[0;32m    207\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m         disable_tqdm\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mdisable_tqdm,\n\u001b[0;32m    215\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset with trust_remote_code=True\n",
    "dataset = load_dataset('wiki_dpr', 'psgs_w100.nq.exact', split='train', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5adc924f7e433199d723586075544a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/157 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd26decb479b4c609d6bee25207bbd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00052-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae152f09acc4048878fae8f5028056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00054-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc18833c3da4269975c0b098f4ec5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00055-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae87d4c5c2b4327b9bdf31acc307bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00056-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f6d89bf7594e18a6cd253f5dd64797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00057-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2899b3d170e64331bfba0d3a307d83b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00058-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c6c39d947b4e9b87ede463d092f84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00059-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2420c06959242688d86c87f1d1eb99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00060-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8853f7853e64d37a0784e3c4b30c575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00061-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425e092932774347b7522f385d3ce643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00062-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9173dbc433a34fd2809dd738effc2975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00063-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af016848588b433da2572cbf81a7505d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00064-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4410046cb324d92959bb0f613a5e427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00065-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c85839a247b43b397675f9aa05bcff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00066-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8a796821e94a8fb0ec80de491f67a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00067-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e95bb6997c4f7689d969d735b2df9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00068-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe282e9d424ccdaf983c9c90b65d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00069-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4966279f2744018ddb071b6c354479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00070-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5d92922ed44363ae8c95ddc4e07758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00071-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d64687c81c402bae14c124802e4735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00072-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e47a7364f045fd901aeeae5efb7e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00073-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab08e528a414b8ea56d523fd5622508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00074-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94186ebeee1b430b8e69ea3af7c7d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00075-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6121bdde4114119ba58069a18aa1129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00076-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7ad37c91af4d4d9a94ff0b51d5065d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00077-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d563a5392a24500b6913c916fb2b591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00078-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d428292a3524d02868ea3b2a0bd4adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00079-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8413d3d45d5341cd8105dfc6c140c87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00080-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7a2388c722408f9acb8ee6b59ff250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00081-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f14da89edf4ddab88cf7c8afa936c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00082-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae371b598c5491194e131e9b6d755e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00083-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe4d7758c8946b68dfb905f3f8903e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00084-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e247df776ed94971a239d21943f107f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00085-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e28cdba0e5443298afb8c300a32872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00086-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58f8dde0c31484c95b26dda3edbce8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00087-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6987b8432f534cbca1d645c0b93aa5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00088-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31b37f6a82d48548f9fa0ac9601a1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00089-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05921bdb50a4eb4a0d6245f8069ff7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00090-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b56eb6fa3a48f89b754d120b8ff681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00091-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1715992e61ee456c9434514af0d504df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00092-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce4fd4c807f447098ab5a27c0b67f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00093-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5550136f0f304f9aa865d0576a9a91ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00094-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737d0611d75a4bea8735feb0ad1ef365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00095-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4de7c53ac004310954c60f4434f78d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00096-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d986dd3eb994f77ac19ed6133005a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00097-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8f1e31807f4826b4b24d9aa43e1190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00098-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb2fe67dbf4295a895eadf1f90aae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00099-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116d58e7540445a18f57a68516aca819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00100-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9358e3115094956b63a4258e2359adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00101-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029a9c156d2c41f08e4c4a03896c9e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00102-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b4b89725f7450bb89804b3299693fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00103-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6258d1c0298f4d3899de98f494f24483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00104-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bd82b98c124d61905e2b4947119d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00105-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f13f293c8094648a3583d6446c77ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00106-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a09ce596d042728d801a3896938472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00107-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad23ae2302e478385a13ce0c88d263b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00108-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe1c53300d34944bb68c12b26b58184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00109-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb17e0badcc4cca82e82f63d01711ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00110-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb905bb52cd45d2a9bed7c918ebd441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00111-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680a882cfb9c4bbbb88d7fc666198535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00112-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2a7698994047fcb6854c51829cdedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00113-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a63e1332964063ab9770cb64396f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00114-of-00157.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6c1d2f4ef5477ba55e00073c1a7b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00115-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25628ca87eb34f819175fe778eaf6f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00116-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33a525aec0479fbc2bd6b79e73ddbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00117-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c768a38d344da19fa935b3772dd566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00118-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b8cd8596fb4725a2e9ccdd72da9236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00119-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1019689446a5437286fd802b948298af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00120-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aff4683f674cc0a8001bf58fcd4264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00121-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbed597085774d4399e4df4d5f593c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00122-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6f9d0f78cf444695ef0fb505798de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00123-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5075d8d83ced4fbab219c6fb5ea21ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00124-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df95f32847c74dbc9a604cbd48dd7d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00125-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc7d8539f3e4dbca857315594d6a6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00126-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92788f547cfe4740884cba281066719e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00127-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087974c448e24d7cad6895f2585965c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00128-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c93f3329bd4e9daf62247b70651fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00129-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e038f6401143268177a4a528fb7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00130-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00bf26fc1174e5b90fbd759805286e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00131-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f705c16b01f4cbfb43c23a3d418ee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00132-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fb9319289949119a81e9cf4c99157a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00133-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f5271bcc834d4cb891e975d802c13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00134-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090fdb428d714b97bf04a8d92ba1fb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00135-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7cf4f6a3b4f42859c2cd32be97d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00136-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d64f37d127443ea6f0996bf8b88523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00137-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789048c50f804215af55086fa724cc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00138-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79527aea190b466986706a9937a790f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00139-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2218ce3f9c4dbcb6d3178bad93bfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00140-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59259a73d45041a28a8c34313cfec7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00141-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01beccf33a1b499e8709b2fd0f9c5cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00142-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bd839783e9465e85657873b9d783df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00143-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9134b4cc1a4f4083b0e250cd76816d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00144-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d88296587642b5bdf55d926626a49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00145-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef499360917e4f0894560702f386b985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00146-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa21efec762a48c384d3435b56c89aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00147-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcf06c426024bb09946e1b95654ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00148-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8428d0843b47c4b88b17c7a801a19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00149-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadbd1c7e1444954be2b9ce27484bd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00150-of-00157.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11dd111a5d5431dbda80ff86a776fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00151-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6ed904eab94dc2ad96917c16b44b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00152-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4b360229fc4026bcb099828942c1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00153-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977ab7c3c9d2452086aa8d0af2e73709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00154-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f0a5f2e564690acc0234defe48fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00155-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef92df2eeeeb49f6922e9d52baf38520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00156-of-00157.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7161cdf6b8294a56afeeac3b1a5759bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/21015300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45edcceadfe24af4a9404abe5e4def5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcca4f404804c158e7b48e891a74336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/157 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0454f03a3db6413a85a8b23a6de0db8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/21015300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e9c14d7e6d483182379591e313ae6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "psgs_w100.nq.HNSW128_SQ8-IP-train.faiss:   0%|          | 0.00/38.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b3a83513e944f5adc8ddc7efef540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e65b70be294d6ebcc5f66a4478c627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "std::bad_alloc",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15228\\3394133273.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagTokenForGeneration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load the RAG retriever and tokenizer separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mretriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-token-base\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rag_token_base\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"retriever\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-token-base/tokenizer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagTokenForGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-token-base/tokenizer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"custom\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomHFIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_vector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexed_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         return cls(\n\u001b[0m\u001b[0;32m    453\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[0mquestion_encoder_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_encoder_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mgenerator_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, config, question_encoder_tokenizer, generator_tokenizer, index, init_retrieval)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_retrieval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx_encoder_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_tokenized_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mRetriever\u001b[0m \u001b[0minitialization\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mIt\u001b[0m \u001b[0mloads\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0minto\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initializing retrieval\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mLoading index from \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_path\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_faiss_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mLoading index from \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m with index name \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             self.dataset = load_dataset(\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[0mwith_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwith_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2159\u001b[0m     \u001b[1;31m# Build dataset for splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m     keep_in_memory = (\n\u001b[0;32m   2161\u001b[0m         \u001b[0mkeep_in_memory\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkeep_in_memory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mis_small_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuilder_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_infos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m         \u001b[0mbuilder_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_infos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mverification_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVerificationMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverification_mode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mVerificationMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBASIC_CHECKS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[1;31m# Create a dataset for each of the given splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         datasets = map_nested(\n\u001b[0m\u001b[0;32m   1127\u001b[0m             partial(\n\u001b[0;32m   1128\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_single_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mrun_post_process\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_post_process\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;31m# Singleton\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[0mdata_struct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             resources_paths = {\n\u001b[0;32m   1165\u001b[0m                 \u001b[0mresource_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_file_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_processing_resources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mpost_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresources_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpost_processed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m                 \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpost_processed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                 \u001b[0mrecorded_checksums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\wiki_dpr\\66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c\\wiki_dpr.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dataset, resources_paths)\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"exact\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexHNSWSQ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScalarQuantizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQT_8bit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_INNER_PRODUCT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnsw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefConstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnsw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefSearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_faiss_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                     \u001b[0mquantizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexHNSWFlat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_INNER_PRODUCT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                     \u001b[0mquantizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnsw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefConstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, column, index_name, device, string_factory, metric_type, custom_index, batch_size, train_size, faiss_verbose, dtype)\u001b[0m\n\u001b[0;32m   5773\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrieved_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nearest_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'embeddings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my new query'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5774\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5775\u001b[0m         \"\"\"\n\u001b[0;32m   5776\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatted_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5777\u001b[1;33m             super().add_faiss_index(\n\u001b[0m\u001b[0;32m   5778\u001b[0m                 \u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5779\u001b[0m                 \u001b[0mindex_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5780\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\search.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, column, index_name, device, string_factory, metric_type, custom_index, batch_size, train_size, faiss_verbose)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mindex_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         faiss_index = FaissIndex(\n\u001b[0;32m    488\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstring_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         faiss_index.add_vectors(\n\u001b[0m\u001b[0;32m    491\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaiss_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfaiss_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\datasets\\search.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, vectors, column, batch_size, train_size, faiss_verbose)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;31m# Add vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mAdding \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m vectors to the faiss index\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaiss_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\faiss\\class_wrappers.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Latif-Calder√≥n\\anaconda3\\Lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, n, x)\u001b[0m\n\u001b[0;32m   6788\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6789\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexHNSW_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: std::bad_alloc"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import RagRetriever, RagTokenizer, RagTokenForGeneration\n",
    "\n",
    "# Load the RAG retriever and tokenizer separately\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\", model_type=\"rag_token_base\", model_name=\"retriever\", trust_remote_code=True)\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base/tokenizer\", trust_remote_code=True)\n",
    "generator = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-base/tokenizer\", trust_remote_code=True)\n",
    "\n",
    "# Folder paths and the remainder of your data processing code should follow here\n",
    "# Folder paths\n",
    "folders = [\"elmundo_chunked_en_page1_15years\", \"elmundo_chunked_es_page1_15years\", \n",
    "           \"elmundo_chunked_es_page1_40years\", \"landmarks\", \"municipalities\"]\n",
    "data_directory = 'data'\n",
    "\n",
    "# Dictionary to store extracted information\n",
    "data = {}\n",
    "\n",
    "# Retrieve information from text files in specified folders\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_directory, folder)\n",
    "    data[folder] = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                text = file.read()\n",
    "                data[folder].append(text)\n",
    "\n",
    "# Index the extracted information\n",
    "indexed_data = {key: tokenizer(value, return_tensors=\"pt\") for key, value in data.items()}\n",
    "\n",
    "# Function to query the RAG model for answers\n",
    "def query_rag_model(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = generator(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask']).choices\n",
    "    return outputs\n",
    "\n",
    "# Ask a question and retrieve an answer using the RAG model\n",
    "question = \"What are the landmarks in Puerto Rico?\"\n",
    "answer = query_rag_model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load and trim dataset\n",
    "dataset = load_dataset('wiki_dpr', 'psgs_w100.nq.exact', split=\"train[:10%]\")  # Just take 10% for testing\n",
    "\n",
    "def embed_data(batch):\n",
    "    # Placeholder for generating embeddings\n",
    "    return {\"embeddings\": model.embed(batch[\"text\"])}\n",
    "\n",
    "\n",
    "\n",
    "# Embedding in smaller batches\n",
    "dataset = dataset.map(embed_data, batched=True, batch_size=16) \n",
    "\n",
    "# Using Faiss for indexing part of the data\n",
    "import faiss\n",
    "\n",
    "d = 768  # Dimensionality of embeddings\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Add embeddings in increments\n",
    "for i in range(0, len(dataset), 1000):\n",
    "    emb_batch = np.array(dataset[\"embeddings\"][i:i+1000])\n",
    "    index.add(emb_batch.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
